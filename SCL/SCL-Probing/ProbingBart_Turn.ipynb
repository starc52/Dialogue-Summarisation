{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oK_TzYwpd1LqlSQBx12p_j3JTVWrRSqB","timestamp":1670085949813},{"file_id":"1ahseFGDVwY8yEmegHemMCoQC2houCqpA","timestamp":1668264569189}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"6412288d823d4d7aa61d379731f2a638":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f35cd6cdf86041e684ce95c9a76d4ccf","IPY_MODEL_634ad89c37074863a40f002577271c5c","IPY_MODEL_6c71066242284ff5b870aff9e5954aff"],"layout":"IPY_MODEL_4b99e0c23fa546eaa5e666b528665ae4"}},"f35cd6cdf86041e684ce95c9a76d4ccf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5a2957d915d41378e8b367482a19363","placeholder":"​","style":"IPY_MODEL_7009577634324dd9896ae5db36928f7b","value":"100%"}},"634ad89c37074863a40f002577271c5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1838fb8339045938b1bfac66e35b08a","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98b704595fd64ef0869b683d10fcd131","value":3}},"6c71066242284ff5b870aff9e5954aff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1039356c70451b928de46bdf59fd7c","placeholder":"​","style":"IPY_MODEL_fb404c22cdee435eb5b811ef6bd39e50","value":" 3/3 [00:00&lt;00:00, 38.00it/s]"}},"4b99e0c23fa546eaa5e666b528665ae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a2957d915d41378e8b367482a19363":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7009577634324dd9896ae5db36928f7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1838fb8339045938b1bfac66e35b08a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b704595fd64ef0869b683d10fcd131":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed1039356c70451b928de46bdf59fd7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb404c22cdee435eb5b811ef6bd39e50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c37c63749a5b44c1baeed3977ee2e873":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98b1e4dcee534e12a8c98a2ed5570bca","IPY_MODEL_b8edb3eb2a1041fa83da2264e34581bf","IPY_MODEL_5bee9370ab1f4c85a507795e45caf71a"],"layout":"IPY_MODEL_65aca1e8752f4b6aab3df77347a269e7"}},"98b1e4dcee534e12a8c98a2ed5570bca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5d3fa92d77e4939be8a500c807edadf","placeholder":"​","style":"IPY_MODEL_1e70350d276a420bad27f737225da5e6","value":"100%"}},"b8edb3eb2a1041fa83da2264e34581bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f5560dda5674266af731636687b5802","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30e6af064e194d749c3df623a86b782d","value":1}},"5bee9370ab1f4c85a507795e45caf71a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_495829aa2e32478e98112498f8611112","placeholder":"​","style":"IPY_MODEL_1cd2d571fe3b41528d8a773a42033b3c","value":" 1/1 [00:01&lt;00:00,  1.28s/ba]"}},"65aca1e8752f4b6aab3df77347a269e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5d3fa92d77e4939be8a500c807edadf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e70350d276a420bad27f737225da5e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f5560dda5674266af731636687b5802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e6af064e194d749c3df623a86b782d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"495829aa2e32478e98112498f8611112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd2d571fe3b41528d8a773a42033b3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"metadata":{"id":"gMzbM4naD2g9","executionInfo":{"status":"ok","timestamp":1670473134830,"user_tz":300,"elapsed":6,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install wandb\n","!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHu9oO2Vqiud","executionInfo":{"status":"ok","timestamp":1670473143710,"user_tz":300,"elapsed":8885,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"a22e30a8-8055-4587-dcb5-c4a0fc1f765c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.6)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.0.11)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.29)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstarc52\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["import wandb\n","\n","wandb.init(project=\"BARTProbing\", entity=\"starc52\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"xwFTxxJiqwvI","executionInfo":{"status":"ok","timestamp":1670473147344,"user_tz":300,"elapsed":3659,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"b87c782b-6f9b-4532-f83d-75bcd0b53c95"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstarc52\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221208_041905-15i8jkb5</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/starc52/BARTProbing/runs/15i8jkb5\" target=\"_blank\">young-surf-24</a></strong> to <a href=\"https://wandb.ai/starc52/BARTProbing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/starc52/BARTProbing/runs/15i8jkb5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7fc5cf08a040>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    \n","    print('Memory Usage:',round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On8STYHmSKtA","executionInfo":{"status":"ok","timestamp":1670473148668,"user_tz":300,"elapsed":1350,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"908ddfb9-be2e-4c09-834c-69fbbd14823a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","Tesla T4\n","Memory Usage: 14.8 GB\n","Allocated: 0.0 GB\n","Cached:    0.0 GB\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py:395: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import random\n","\n","def set_random_seed(seed):\n","     torch.manual_seed(seed)\n","     torch.cuda.manual_seed_all(seed)\n","     np.random.seed(seed)\n","     random.seed(seed)\n","     torch.backends.cudnn.deterministic = True\n","set_random_seed(0)"],"metadata":{"id":"faaqh5xzw8pI","executionInfo":{"status":"ok","timestamp":1670473148670,"user_tz":300,"elapsed":6,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOsHUjgdIrIW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e7e5cf9-327f-48ae-ea8a-80c8442a7556","executionInfo":{"status":"ok","timestamp":1670473154099,"user_tz":300,"elapsed":5434,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["! pip install datasets transformers rouge-score nltk py7zr"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.8/dist-packages (0.1.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: py7zr in /usr/local/lib/python3.8/dist-packages (0.20.2)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: texttable in /usr/local/lib/python3.8/dist-packages (from py7zr) (1.6.7)\n","Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.8/dist-packages (from py7zr) (0.15.3)\n","Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from py7zr) (1.0.1)\n","Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from py7zr) (3.16.0)\n","Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from py7zr) (1.0.0)\n","Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.8/dist-packages (from py7zr) (1.0.9)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.8/dist-packages (from py7zr) (0.2.3)\n","Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from py7zr) (0.3.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from py7zr) (5.4.8)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n"]}]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"e-v6Mjk_JvG3","executionInfo":{"status":"ok","timestamp":1670473154101,"user_tz":300,"elapsed":26,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# %cd /content/drive/MyDrive/NLP Project with SCL"],"metadata":{"id":"z5nOd8wBL-BO","executionInfo":{"status":"ok","timestamp":1670473154278,"user_tz":300,"elapsed":193,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["# Fine-tuning a model on a summarization task"]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","metadata":{"id":"IreSlFmlIrIm","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["6412288d823d4d7aa61d379731f2a638","f35cd6cdf86041e684ce95c9a76d4ccf","634ad89c37074863a40f002577271c5c","6c71066242284ff5b870aff9e5954aff","4b99e0c23fa546eaa5e666b528665ae4","a5a2957d915d41378e8b367482a19363","7009577634324dd9896ae5db36928f7b","d1838fb8339045938b1bfac66e35b08a","98b704595fd64ef0869b683d10fcd131","ed1039356c70451b928de46bdf59fd7c","fb404c22cdee435eb5b811ef6bd39e50"]},"outputId":"99f502c9-29b1-4ab4-cd0f-54aa2e999712","executionInfo":{"status":"ok","timestamp":1670473156567,"user_tz":300,"elapsed":2292,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["from datasets import load_dataset, load_metric\n","\n","raw_datasets = load_dataset(\"samsum\")\n","\n","metric = load_metric(\"rouge\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset samsum (/root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6412288d823d4d7aa61d379731f2a638"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-e81e8f9a415c>:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"rouge\")\n"]}]},{"cell_type":"markdown","source":["## BART"],"metadata":{"id":"Ql3_w39HR2zi"}},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["### Preprocessing the data"]},{"cell_type":"code","metadata":{"id":"TkXftRLYwOqc","executionInfo":{"status":"ok","timestamp":1670473156569,"user_tz":300,"elapsed":10,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["model_checkpoint = \"facebook/bart-base\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXNLu_-nIrJI","executionInfo":{"status":"ok","timestamp":1670473159609,"user_tz":300,"elapsed":3048,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def check_token_length(dataset):\n","    ids=[]\n","    for i in range(len(dataset['dialogue'])):\n","        if len(tokenizer(dataset['dialogue'][i])['input_ids'])>1000:\n","            ids.append(i)\n","    print(ids)\n","    return ids\n","def remove_idx(list_idx, dataset):\n","    return dataset.select((\n","          i for i in range(len(dataset)) \n","          if i not in set(list_idx)))\n","    \n","train_ids=check_token_length(raw_datasets['train'])\n","validation_ids=check_token_length(raw_datasets['validation'])\n","test_ids = check_token_length(raw_datasets['test'])\n","changed_datasets_train=remove_idx(train_ids, raw_datasets['train'])\n","changed_datasets_val = remove_idx(validation_ids, raw_datasets['validation'])\n","changed_datasets_test = remove_idx(test_ids, raw_datasets['test'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9hiJeaPFqEK","executionInfo":{"status":"ok","timestamp":1670473440309,"user_tz":300,"elapsed":280716,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"859f5c6d-befc-43b5-9b34-1db662092cfc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["[4269, 8198]\n","[]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.fingerprint:Parameter 'indices'=<generator object remove_idx.<locals>.<genexpr> at 0x7fc4d216a740> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","metadata":{"id":"vc0BSBLIIrJQ","executionInfo":{"status":"ok","timestamp":1670473440312,"user_tz":300,"elapsed":30,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["max_input_length = 1024\n","max_target_length = 128\n","\n","def make_one_hot_sequence(input_ids, sequence_ids):\n","    changed_sequence_id=[0]\n","    token_to_speaker_id={}\n","    uniq_id = 1\n","    for dic in sequence_ids:\n","        if str(input_ids[dic['spk'][0]:dic['spk'][1]]) in token_to_speaker_id:\n","            speaker_id = token_to_speaker_id[str(input_ids[dic['spk'][0]:dic['spk'][1]])]\n","        else:\n","            token_to_speaker_id[str(input_ids[dic['spk'][0]:dic['spk'][1]])] = uniq_id\n","            speaker_id = uniq_id\n","            uniq_id+=1\n","        for _ in range(dic['spk'][0], dic['spk'][1]):\n","            changed_sequence_id.append(speaker_id)\n","        for _ in range(dic['utt'][0], dic['utt'][1]):\n","            changed_sequence_id.append(-1)\n","    changed_sequence_id.append(0)\n","    return changed_sequence_id \n","\n","\n","def preprocess_function(examples): ## hit gold here. change this preprocess function to include speaker and turn information. \n","    slash_n = tokenizer([\"\\r\\n\"])['input_ids'][0][1:-1]\n","    slash_n_mask = tokenizer([\"\\r\\n\"])['attention_mask'][0][1:-1]\n","    inputs_list=[]\n","    masks_list=[]\n","    pos_list=[]\n","    for index in range(len(examples['dialogue'])):\n","        # breaking the dialogue for spk:utt info\n","        broken=[]\n","        for utt in examples['dialogue'][index].split(\"\\r\\n\"):\n","            first_ind = utt.find(':')\n","            broken.append(utt[:first_ind])\n","            broken.append(utt[first_ind:])\n","        \n","        tokenized_broken = tokenizer(broken)['input_ids']\n","        attention_broken = tokenizer(broken)['attention_mask']\n","        \n","        # adding \\r\\n tokens\n","        for i in range(1, len(tokenized_broken)-1, 2):\n","            tokenized_broken[i].insert(-1, slash_n[0])\n","            tokenized_broken[i].insert(-1, slash_n[1])\n","            attention_broken[i].insert(-1, slash_n_mask[0])\n","            attention_broken[i].insert(-1, slash_n_mask[1])\n","        joined = tokenized_broken[0]\n","\n","        # annotating for spk_utt_pos\n","        assoc_dict={}\n","        assoc_dict['spk'] = [1, len(tokenized_broken[0])-1] # the range is actually exclusive of the last index. \n","        odd_bool = True\n","        running_length = len(tokenized_broken[0])\n","        sequence_ids=[]\n","        for inner in tokenized_broken[1:]:\n","            if odd_bool==True:\n","                assoc_dict['utt']=[running_length-1, running_length+len(inner)-3]\n","                odd_bool=False\n","                sequence_ids.append(assoc_dict)\n","                assoc_dict={}\n","            else:\n","                assoc_dict['spk']=[running_length-1, running_length+len(inner)-3]\n","                odd_bool=True\n","            joined = joined[:-1]+inner[1:]\n","            running_length += (len(inner)-2)\n","        \n","        # test for CUDA assert error\n","        if(len(joined)>1024):\n","            print(\"input tokens list length greater than 1024, skipping example\", end=' ')\n","            print(\"equal to\", len(joined))\n","            print(tokenizer.decode(joined))\n","        \n","        # creating inputs list\n","        inputs_list.append(joined)\n","        pos_list.append(make_one_hot_sequence(joined, sequence_ids))\n","        \n","        # creating new mask\n","        joined_mask = attention_broken[0]\n","        for inner_attention in attention_broken[1:]:\n","            joined_mask = joined_mask[:-1]+inner_attention[1:]\n","        masks_list.append(joined_mask)\n","    \n","    # overriding normal model_inputs\n","    inputs = [doc for doc in examples[\"dialogue\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    model_inputs['input_ids'] = inputs_list\n","    model_inputs['attention_mask'] = masks_list\n","    model_inputs['spk_utt_pos'] = pos_list\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDtsaJeVIrJT","executionInfo":{"status":"ok","timestamp":1670473441657,"user_tz":300,"elapsed":1365,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["c37c63749a5b44c1baeed3977ee2e873","98b1e4dcee534e12a8c98a2ed5570bca","b8edb3eb2a1041fa83da2264e34581bf","5bee9370ab1f4c85a507795e45caf71a","65aca1e8752f4b6aab3df77347a269e7","b5d3fa92d77e4939be8a500c807edadf","1e70350d276a420bad27f737225da5e6","8f5560dda5674266af731636687b5802","30e6af064e194d749c3df623a86b782d","495829aa2e32478e98112498f8611112","1cd2d571fe3b41528d8a773a42033b3c"]},"outputId":"2719b55d-894b-4af4-dfd0-2473648334aa"},"source":["tokenized_datasets_train_o = changed_datasets_train.map(preprocess_function, batched=True)\n","tokenized_datasets_val_o = changed_datasets_val.map(preprocess_function, batched=True)\n","tokenized_datasets_test_o = changed_datasets_test.map(preprocess_function, batched=True)\n","\n","# tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n","tokenized_datasets_train = tokenized_datasets_train_o.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_datasets_val = tokenized_datasets_val_o.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_datasets_test = tokenized_datasets_test_o.remove_columns(['id', 'dialogue', 'summary'])"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-5c2266ace14123ef.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-62c11a7f7e94aa2a.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c37c63749a5b44c1baeed3977ee2e873"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print(type(tokenized_datasets_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFZpB8lAckUo","executionInfo":{"status":"ok","timestamp":1670473441659,"user_tz":300,"elapsed":24,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"7d536712-985f-4bd1-8b32-b4ebb290c19c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'datasets.arrow_dataset.Dataset'>\n"]}]},{"cell_type":"code","source":["from transformers import PreTrainedTokenizerBase\n","from transformers.utils import PaddingStrategy\n","from transformers import DataCollatorForSeq2Seq\n","from typing import Optional, Any, Union\n","import numpy as np\n","\n","\n","class CustomCollatorForSeq2Seq(DataCollatorForSeq2Seq):\n","    r\"\"\"\n","    Data collator that will dynamically pad the inputs received, as well as the labels.\n","    Args:\n","        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n","            The tokenizer used for encoding the data.\n","        model ([`PreTrainedModel`]):\n","            The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n","            prepare the *decoder_input_ids*\n","            This is useful when using *label_smoothing* to avoid calculating loss twice.\n","        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n","            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n","            among:\n","            - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single sequence\n","              is provided).\n","            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n","              acceptable input length for the model if that argument is not provided.\n","            - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n","              lengths).\n","        max_length (`int`, *optional*):\n","            Maximum length of the returned list and optionally padding length (see above).\n","        pad_to_multiple_of (`int`, *optional*):\n","            If set will pad the sequence to a multiple of the provided value.\n","            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n","            7.5 (Volta).\n","        label_pad_token_id (`int`, *optional*, defaults to -100):\n","            The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n","        return_tensors (`str`):\n","            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n","    \"\"\"\n","\n","    tokenizer: PreTrainedTokenizerBase\n","    model: Optional[Any] = None\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    label_pad_token_id: int = -100\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features, return_tensors=None):\n","        if return_tensors is None:\n","            return_tensors = self.return_tensors\n","        labels = [feature[\"labels\"] for feature in features] if \"labels\" in features[0].keys() else None\n","        # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n","        # same length to return tensors.\n","        if labels is not None:\n","            max_label_length = max(len(l) for l in labels)\n","            if self.pad_to_multiple_of is not None:\n","                max_label_length = (\n","                        (max_label_length + self.pad_to_multiple_of - 1)\n","                        // self.pad_to_multiple_of\n","                        * self.pad_to_multiple_of\n","                )\n","\n","            padding_side = self.tokenizer.padding_side\n","            for feature in features:\n","                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n","                if isinstance(feature[\"labels\"], list):\n","                    feature[\"labels\"] = (\n","                        feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n","                    )\n","                elif padding_side == \"right\":\n","                    feature[\"labels\"] = np.concatenate([feature[\"labels\"], remainder]).astype(np.int64)\n","                else:\n","                    feature[\"labels\"] = np.concatenate([remainder, feature[\"labels\"]]).astype(np.int64)\n","        # added here\n","        spk_utt_pos = [feature[\"spk_utt_pos\"] for feature in features]\n","        max_spk_utt_pos_length = max(len(l) for l in spk_utt_pos)\n","\n","        if self.pad_to_multiple_of is not None:\n","            max_spk_utt_pos_length = (\n","                    (max_spk_utt_pos_length + self.pad_to_multiple_of - 1)\n","                    // self.pad_to_multiple_of\n","                    * self.pad_to_multiple_of\n","            )\n","\n","        padding_side = self.tokenizer.padding_side\n","        for feature in features:\n","            remainder = [0] * (max_spk_utt_pos_length - len(feature[\"spk_utt_pos\"]))\n","            if isinstance(feature[\"spk_utt_pos\"], list):\n","                feature[\"spk_utt_pos\"] = (\n","                    feature[\"spk_utt_pos\"] + remainder if padding_side == \"right\" else remainder + feature[\n","                        \"spk_utt_pos\"]\n","                )\n","            elif padding_side == \"right\":\n","                feature[\"spk_utt_pos\"] = np.concatenate([feature[\"spk_utt_pos\"], remainder]).astype(np.int64)\n","            else:\n","                feature[\"spk_utt_pos\"] = np.concatenate([remainder, feature[\"spk_utt_pos\"]]).astype(np.int64)\n","\n","        features = self.tokenizer.pad(\n","            features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=return_tensors,\n","        )\n","\n","        # prepare decoder_input_ids\n","        if (\n","                labels is not None\n","                and self.model is not None\n","                and hasattr(self.model, \"prepare_decoder_input_ids_from_labels\")\n","        ):\n","            decoder_input_ids = self.model.prepare_decoder_input_ids_from_labels(labels=features[\"labels\"])\n","            features[\"decoder_input_ids\"] = decoder_input_ids\n","\n","        return features\n"],"metadata":{"id":"HEZHf93mtTx2","executionInfo":{"status":"ok","timestamp":1670473441660,"user_tz":300,"elapsed":18,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["collator = CustomCollatorForSeq2Seq(tokenizer)\n","train_dataloader=torch.utils.data.DataLoader(tokenized_datasets_train, collate_fn=collator)\n"],"metadata":{"id":"x__hUzpmfO3K","executionInfo":{"status":"ok","timestamp":1670473441662,"user_tz":300,"elapsed":17,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["next(iter(train_dataloader))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIeOsBcKfeK9","executionInfo":{"status":"ok","timestamp":1670473441663,"user_tz":300,"elapsed":17,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"bff32b4e-c147-46e3-d9cf-b8951ffb7c90"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    0, 10127,  5219,    35,    38, 17241,  1437, 15269,     4,  1832,\n","            47,   236,   103,   116, 50121, 50118, 39237,    35,  9136,   328,\n","         50121, 50118, 10127,  5219,    35,    38,   581,   836,    47,  3859,\n","         48433,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]]), 'spk_utt_pos': tensor([[ 0,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  2, -1,\n","         -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  0]]), 'labels': tensor([[    0, 10127,  5219, 17241, 15269,     8,    40,   836,  6509,   103,\n","          3859,     4,     2]])}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from torch import nn\n","from transformers import BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers.modeling_utils import unwrap_model\n","from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n","\n","from transformers.models.bart.modeling_bart import BartConfig\n","import torch\n","from typing import *\n","from transformers.modeling_outputs import Seq2SeqLMOutput\n","from transformers.models.bart.modeling_bart import shift_tokens_right\n","import random\n","from tqdm import tqdm\n","import gc\n","import itertools\n","\n","class BartWithSCL(BartForConditionalGeneration):\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","\n","    def set_losses_list(self, SCLossesList=['token']):\n","        self.SCLossesList = SCLossesList\n","    def set_scl_coeff(self, scl_coeff=1e-1):\n","        self.scl_coeff=scl_coeff\n","    def token_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Token Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        spk_utt_states[spk].append(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]])\n","            \n","            \n","            #---------- hitesh------------------------------\n","            # positive samples\n","            # L_pos = 0\n","            # L_neg = 0 \n","\n","            # sampled_spk_utt_states = []           \n","\n","            # for spk in uniq_spks:\n","            #     utts = len(spk_utt_states[spk])\n","            #     spk_utt = []\n","            #     if utts > 1:\n","            #         # ids = random.sample(list(range(len(spk_utt_states[spk]))), random.randint(1, utts))\n","            #         ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","            #         for i in ids:\n","            #           spk_utt.append(spk_utt_states[spk][i])\n","            #     sampled_spk_utt_states.append(spk_utt)\n","\n","            # for instance in sampled_spk_utt_states:\n","            #   for i in range(len(instance)):\n","            #     for j in range(len(instance)):\n","            #       mat_mul = torch.einsum('ij, kj->ik', instance[i], instance[j])\n","            #       sigm = torch.sigmoid(mat_mul)\n","            #       log = torch.log(sigm)\n","            #       L_pos += torch.sum(-1 * log)\n","            # # print(\"L_pos\", L_pos)\n","\n","            # #negative loss\n","            # for i in range(0,len(sampled_spk_utt_states)):\n","            #   instance = sampled_spk_utt_states[i]\n","\n","            #   neg_instances = sampled_spk_utt_states[:i]+sampled_spk_utt_states[i+1:]\n","            #   neg_instances = list(itertools.chain(*neg_instances))\n","            #   # neg_instances = random.choices(neg_instances,k = random.randint(1, len(neg_instances)))\n","            #   if len(neg_instances)>0:\n","            #     # print(len(neg_instances))\n","            #     # print(\"-------------------------\")\n","            #     # print(sampled_spk_utt_states)\n","            #     neg_instances = random.choices(neg_instances,k = 2)\n","            #     for i in range(len(instance)):\n","            #       for j in range(len(neg_instances)):\n","            #         mat_mul = torch.einsum('ij, kj->ik', instance[i], neg_instances[j])\n","            #         sigm = torch.sigmoid(mat_mul)\n","            #         log = torch.log(1 - sigm+1e-5)\n","            #         L_neg += torch.sum(-1 * log)\n","            #---------- hitesh------------------------------\n","            \n","            \n","            # positive samples\n","            L_pos = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","                    id1 = ids[0]\n","                    id2 = ids[1]\n","                    mat_mul = torch.einsum('ij, kj->ik', spk_utt_states[spk][id1], spk_utt_states[spk][id1])\n","                    sigm = torch.sigmoid(mat_mul)\n","                    log = torch.log(sigm)\n","                    L_pos += torch.sum(-1 * log)\n","                    L_pos = torch.nan_to_num(L_pos, posinf = 1e10, neginf = -1e10)\n","            # print(\"L_pos\", L_pos)\n","            # negative samples\n","            \n","            L_neg = 0\n","            for spk in uniq_spks:\n","                new_uniq_spks = uniq_spks.copy()\n","                new_uniq_spks.remove(spk)\n","\n","                spk2 = random.choice(new_uniq_spks)\n","\n","                id1 = random.randint(0, len(spk_utt_states[spk])-1)\n","                id2 = random.randint(0, len(spk_utt_states[spk2])-1)\n","\n","                mat_mul = torch.einsum('ij, kj->ik', spk_utt_states[spk][id1], spk_utt_states[spk2][id2])\n","                sigm = torch.sigmoid(mat_mul)\n","                # print(1 - sigm)\n","                # print(1 - sigm+1e-5)\n","                log = torch.log(1 - sigm+1e-5)\n","                L_neg += torch.sum(-1 * log)\n","                \n","                L_neg = torch.nan_to_num(L_neg, posinf = 1e10, neginf = -1e10)\n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-token\", batch_scl})\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","    \n","    def turn_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Turn Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        mean_pool = torch.mean(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]], 0)\n","                        spk_utt_states[spk].append(mean_pool)\n","\n","            # positive samples\n","            L_pos = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","                    id1 = ids[0]\n","                    id2 = ids[1]\n","                    mat_mul = torch.einsum('i, j->', spk_utt_states[spk][id1], spk_utt_states[spk][id1])\n","                    sigm = torch.sigmoid(mat_mul)\n","                    log = torch.log(sigm)\n","                    L_pos += torch.sum(-1 * log)\n","                    # L_pos = torch.nan_to_num(L_pos, posinf = 1e10, neginf = -1e10)\n","            # print(\"L_pos\", L_pos)\n","            # negative samples\n","            L_neg = 0\n","            for spk in uniq_spks:\n","                new_uniq_spks = uniq_spks.copy()\n","                new_uniq_spks.remove(spk)\n","\n","                spk2 = random.choice(new_uniq_spks)\n","\n","                id1 = random.randint(0, len(spk_utt_states[spk])-1)\n","                id2 = random.randint(0, len(spk_utt_states[spk2])-1)\n","\n","                mat_mul = torch.einsum('i, j->', spk_utt_states[spk][id1], spk_utt_states[spk2][id2])\n","                sigm = torch.sigmoid(mat_mul)\n","                # print(1 - sigm)\n","                # print(1 - sigm+1e-5)\n","                log = torch.log(1 - sigm+1e-5)\n","                L_neg += torch.sum(-1 * log)\n","                \n","                # L_neg = torch.nan_to_num(L_neg, posinf = 1e10, neginf = -1e10)\n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-turn\", batch_scl})\n","\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","    \n","    def global_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Turn Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        mean_pool = torch.mean(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]], 0)\n","                        spk_utt_states[spk].append(mean_pool)\n","\n","            # positive samples\n","            L_pos = 0\n","            L_neg = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.choice(list(range(len(spk_utt_states[spk]))))\n","                    \n","                    spk_mean_exc = torch.mean(torch.vstack([spk_utt_states[spk][temp] for temp in range(len(spk_utt_states[spk])) if temp != ids]), 0)\n","                    \n","                    pos_mat_mul = torch.einsum('i, j->', spk_utt_states[spk][ids], spk_mean_exc)\n","                    pos_sigm = torch.sigmoid(pos_mat_mul)\n","                    pos_log = torch.log(pos_sigm)\n","                    L_pos += torch.sum(-1 * pos_log)\n","\n","                    # negative sample\n","\n","                    new_uniq_spks = uniq_spks.copy()\n","                    new_uniq_spks.remove(spk)\n","                    \n","                    spk2 = random.choice(new_uniq_spks)\n","                    id_neg = random.choice(list(range(len(spk_utt_states[spk2]))))\n","                    neg_mat_mul = torch.einsum('i, j->', spk_utt_states[spk2][id_neg], spk_mean_exc)\n","                    neg_sigm = torch.sigmoid(neg_mat_mul)\n","                    neg_log = torch.log(1 - neg_sigm+1e-5)\n","                    L_neg += torch.sum(-1 * neg_log)\n","                \n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-global\", batch_scl})\n","\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","\n","    def forward(\n","        self,\n","        input_ids: torch.LongTensor = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        spk_utt_pos: Optional[torch.Tensor] = None, ##changed here\n","        decoder_input_ids: Optional[torch.LongTensor] = None,\n","        decoder_attention_mask: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.Tensor] = None,\n","        decoder_head_mask: Optional[torch.Tensor] = None,\n","        cross_attn_head_mask: Optional[torch.Tensor] = None,\n","        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n","        past_key_values: Optional[List[torch.FloatTensor]] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        use_cache: Optional[bool] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","        ) -> Union[Tuple, Seq2SeqLMOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n","            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n","            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n","        Returns:\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if labels is not None:\n","            if use_cache:\n","                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n","            use_cache = False\n","            if decoder_input_ids is None and decoder_inputs_embeds is None:\n","                decoder_input_ids = shift_tokens_right(\n","                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n","                )\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            encoder_outputs=encoder_outputs,\n","            decoder_attention_mask=decoder_attention_mask,\n","            head_mask=head_mask,\n","            decoder_head_mask=decoder_head_mask,\n","            cross_attn_head_mask=cross_attn_head_mask,\n","            past_key_values=past_key_values,\n","            inputs_embeds=inputs_embeds,\n","            decoder_inputs_embeds=decoder_inputs_embeds,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        if encoder_outputs is None:\n","            encoder = self.get_encoder()\n","            # TODO: mask the speaker names from the input IDs using the speaker pos info\n","            turn_attention_mask=None\n","            token_encoder_outputs=None\n","            tog_encoder_outputs=None\n","            \n","            if 'token' in self.SCLossesList:\n","                token_encoder_outputs = encoder(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    head_mask=head_mask,\n","                    inputs_embeds=inputs_embeds,\n","                    output_attentions=output_attentions,\n","                    output_hidden_states=output_hidden_states,\n","                    return_dict=return_dict,\n","                )\n","\n","            if 'turn' in self.SCLossesList or 'global' in self.SCLossesList:\n","                tog_attention_mask = torch.where(spk_utt_pos>0, 0, attention_mask)\n","                tog_encoder_outputs = encoder(\n","                    input_ids=input_ids,\n","                    attention_mask=tog_attention_mask,\n","                    head_mask=head_mask,\n","                    inputs_embeds=inputs_embeds,\n","                    output_attentions=output_attentions,\n","                    output_hidden_states=output_hidden_states,\n","                    return_dict=return_dict,\n","                )\n","        # if 'hidden_states' in encoder_outputs:\n","        #     print(\"encoder_outputs['last_hidden_state'].size(), encoder_outputs['hidden_states'].size()\",\n","        #     encoder_outputs['last_hidden_state'].size(), encoder_outputs['hidden_states'].size())\n","        # else:\n","        #     print(\"encoder_outputs['last_hidden_state'].size()\", encoder_outputs['last_hidden_state'].size())\n","\n","        lm_logits = self.lm_head(outputs[0])\n","        lm_logits = lm_logits + self.final_logits_bias.to(lm_logits.device)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = torch.nn.CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n","        # added here\n","        sc_loss = 0\n","        if 'token' in self.SCLossesList and labels is not None:\n","            sc_loss += self.token_scl(last_hidden_state=token_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","            # print(sc_loss)\n","        if 'turn' in self.SCLossesList and labels is not None:\n","            sc_loss += self.turn_scl(last_hidden_state=tog_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","        \n","        if 'global' in self.SCLossesList and labels is not None:\n","            sc_loss += self.global_scl(last_hidden_state=tog_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","        \n","        if not return_dict:\n","            output = (lm_logits,) + outputs[1:]\n","            return ((masked_lm_loss+(self.scl_coeff*sc_loss),) + output) if masked_lm_loss is not None else output\n","        loss = None\n","        if masked_lm_loss is None:\n","            loss = None\n","        else:\n","            loss = masked_lm_loss+(self.scl_coeff*sc_loss)\n","        return Seq2SeqLMOutput(\n","            loss=loss,\n","            logits=lm_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            cross_attentions=outputs.cross_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","\n","class ProbingBart(nn.Module):\n","    def __init__(self, bart_path):\n","        super(ProbingBart, self).__init__()\n","        self.bart = BartWithSCL.from_pretrained(bart_path)\n","        for param in self.bart.parameters():\n","            param.requires_grad = False\n","        self.bart_encoder = self.bart.get_encoder()\n","\n","        self.probing_mlp_1 = nn.Linear(in_features=768*2, out_features=512)\n","        self.relu = nn.ReLU()\n","        self.probing_mlp_2 = nn.Linear(in_features=512, out_features=1)\n","    \n","    def get_probing_batches(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Token Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        pos_batch=[]\n","        neg_batch=[]\n","\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        spk_utt_states[spk].append(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]])\n","            \n","            pos = []\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","                    id1 = ids[0]\n","                    id2 = ids[1]\n","                    token_id1 = random.choice(list(range(len(spk_utt_states[spk][id1]))))\n","                    token_id2 = random.choice(list(range(len(spk_utt_states[spk][id2]))))\n","                    pos.append(torch.cat([spk_utt_states[spk][id1][token_id1], spk_utt_states[spk][id2][token_id2]], dim=0))\n","            if len(pos)==0:\n","                continue\n","            neg = []\n","            for spk in uniq_spks:\n","                new_uniq_spks = uniq_spks.copy()\n","                new_uniq_spks.remove(spk)\n","\n","                spk2 = random.choice(new_uniq_spks)\n","\n","                id1 = random.randint(0, len(spk_utt_states[spk])-1)\n","                id2 = random.randint(0, len(spk_utt_states[spk2])-1)\n","                token_id1 = random.choice(list(range(len(spk_utt_states[spk][id1]))))\n","                token_id2 = random.choice(list(range(len(spk_utt_states[spk2][id2]))))\n","                neg.append(torch.cat([spk_utt_states[spk][id1][token_id1], spk_utt_states[spk2][id2][token_id2]], dim=0))\n","            pos_batch.append(torch.vstack(pos))\n","            neg_batch.append(torch.vstack(neg))\n","        pos_batch = torch.vstack(pos_batch)\n","        neg_batch = torch.vstack(neg_batch)\n","        return pos_batch, neg_batch\n","    \n","    def forward(\n","        self,\n","        input_ids: torch.LongTensor = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        spk_utt_pos: Optional[torch.Tensor] = None, ##changed here\n","        decoder_input_ids: Optional[torch.LongTensor] = None,\n","        decoder_attention_mask: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.Tensor] = None,\n","        decoder_head_mask: Optional[torch.Tensor] = None,\n","        cross_attn_head_mask: Optional[torch.Tensor] = None,\n","        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n","        past_key_values: Optional[List[torch.FloatTensor]] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        use_cache: Optional[bool] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","        ) -> Union[Tuple, Seq2SeqLMOutput]:\n","        if encoder_outputs is None:            \n","            encoder_outputs = self.bart_encoder(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                head_mask=head_mask,\n","                inputs_embeds=inputs_embeds,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        pos_batch, neg_batch = self.get_probing_batches(\n","            last_hidden_state=encoder_outputs['last_hidden_state'], \n","            spk_utt_pos = spk_utt_pos)\n","        out_pos = self.probing_mlp_1(pos_batch)\n","        out_pos = self.relu(out_pos)\n","        out_pos = self.probing_mlp_2(out_pos)\n","        out_pos = 1/(1+torch.exp(-out_pos))\n","\n","        out_neg = self.probing_mlp_1(neg_batch)\n","        out_neg = self.relu(out_neg)\n","        out_neg = self.probing_mlp_2(out_neg)\n","        out_neg = 1/(1+torch.exp(-out_neg))\n","\n","\n","        bce = nn.BCELoss()\n","        ones = torch.unsqueeze(torch.ones(pos_batch.size(0)), 1).to(device)\n","        zeros = torch.unsqueeze(torch.zeros(neg_batch.size(0)), 1).to(device)\n","        pos_bce = bce(out_pos, ones)\n","        neg_bce = bce(out_neg, zeros)\n","\n","        loss=pos_bce+neg_bce  \n","        return loss, out_pos, out_neg"],"metadata":{"id":"nEvSIc03tW7d","executionInfo":{"status":"ok","timestamp":1670473441930,"user_tz":300,"elapsed":7,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV"},"source":["### Fine-tuning the model"]},{"cell_type":"code","metadata":{"id":"TlqNaB8jIrJW","executionInfo":{"status":"ok","timestamp":1670473441932,"user_tz":300,"elapsed":7,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"source":["# from models import BartWithSCL\n","# from datacollator import CustomCollatorForSeq2Seq\n","# from trainer import CustomTrainer\n","\n","\n","from transformers import BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers.modeling_utils import unwrap_model\n","from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPp4WJNzhgw2","executionInfo":{"status":"ok","timestamp":1670473442837,"user_tz":300,"elapsed":911,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"b804ada6-72ae-463b-80f9-4ff4c2668fca"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","model = ProbingBart('/content/drive/MyDrive/NLP Project with SCL/test-turn-batch6/checkpoint-6000')\n","model.to(device)\n","# model.set_losses_list(['token'])\n","# model.set_scl_coeff(0.1)"],"metadata":{"id":"Khz2QvEoBYcH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670473450175,"user_tz":300,"elapsed":7342,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}},"outputId":"b33e4a56-ffbf-4b00-82b9-8c2a7eda6b1c"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ProbingBart(\n","  (bart): BartWithSCL(\n","    (model): BartModel(\n","      (shared): Embedding(50265, 768, padding_idx=1)\n","      (encoder): BartEncoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (decoder): BartDecoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n","  )\n","  (bart_encoder): BartEncoder(\n","    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","    (layers): ModuleList(\n","      (0): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): BartEncoderLayer(\n","        (self_attn): BartAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (activation_fn): GELUActivation()\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (probing_mlp_1): Linear(in_features=1536, out_features=512, bias=True)\n","  (relu): ReLU()\n","  (probing_mlp_2): Linear(in_features=512, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["data_collator = CustomCollatorForSeq2Seq(tokenizer)\n","train_dataloader = torch.utils.data.DataLoader(tokenized_datasets_train, batch_size=64, collate_fn=data_collator, num_workers=2)\n","val_dataloader = torch.utils.data.DataLoader(tokenized_datasets_val, batch_size=64, collate_fn=data_collator, num_workers=2)\n","test_dataloader = torch.utils.data.DataLoader(tokenized_datasets_test, batch_size=64, collate_fn=data_collator, num_workers=2)"],"metadata":{"id":"fhYv33h74na-","executionInfo":{"status":"ok","timestamp":1670473450176,"user_tz":300,"elapsed":39,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from keras.utils import np_utils\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","EPOCHS=10\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for inputs in tqdm(train_dataloader):\n","\n","        loss, out_pos, out_neg = model(input_ids=inputs['input_ids'].to(device), \n","              attention_mask = inputs['attention_mask'].to(device), \n","              spk_utt_pos = inputs['spk_utt_pos'].to(device))\n","        \n","        \n","        wandb.log({'loss': loss})\n","\n","\n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    accuracy=0\n","    total_num=0\n","    for inputs in tqdm(val_dataloader):\n","        loss, out_pos, out_neg = model(input_ids=inputs['input_ids'].to(device), \n","              attention_mask = inputs['attention_mask'].to(device), \n","              spk_utt_pos = inputs['spk_utt_pos'].to(device))\n","        pos_pred = torch.squeeze(out_pos).detach().cpu().numpy()\n","        ones = np.ones(pos_pred.shape[0])\n","        neg_pred = torch.squeeze(out_neg).detach().cpu().numpy()\n","        zeros = np.zeros(neg_pred.shape[0])\n","        pred = np.hstack([pos_pred, neg_pred])\n","        binary_pred = np.where(pred>0.7, 1, 0)\n","        target = np.hstack([ones, zeros])\n","        accuracy += accuracy_score(target, binary_pred)\n","        total_num+=1\n","    print(accuracy/total_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":556},"id":"R1QayReGinUc","outputId":"3ae876b2-1f07-495b-eb73-03417114e1fb","executionInfo":{"status":"error","timestamp":1670475187841,"user_tz":300,"elapsed":1737694,"user":{"displayName":"Sai Tanmay Reddy","userId":"13202642314045427358"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [08:23<00:00,  2.18s/it]\n","100%|██████████| 13/13 [00:27<00:00,  2.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["0.5700912043330049\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [08:39<00:00,  2.25s/it]\n","100%|██████████| 13/13 [00:29<00:00,  2.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["0.6208570402587139\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231/231 [08:35<00:00,  2.23s/it]\n","100%|██████████| 13/13 [00:28<00:00,  2.22s/it]\n"]},{"output_type":"stream","name":"stdout","text":["0.6437583334038123\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 51/231 [01:53<06:39,  2.22s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-05f61bd9aa92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         loss, out_pos, out_neg = model(input_ids=inputs['input_ids'].to(device), \n\u001b[0m\u001b[1;32m     12\u001b[0m               \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m               spk_utt_pos = inputs['spk_utt_pos'].to(device))\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-48d7f2905248>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, spk_utt_pos, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             )\n\u001b[0;32m--> 623\u001b[0;31m         pos_batch, neg_batch = self.get_probing_batches(\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             spk_utt_pos = spk_utt_pos)\n","\u001b[0;32m<ipython-input-19-48d7f2905248>\u001b[0m in \u001b[0;36mget_probing_batches\u001b[0;34m(self, last_hidden_state, spk_utt_pos)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mutt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spk_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                     \u001b[0mutt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mutt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}