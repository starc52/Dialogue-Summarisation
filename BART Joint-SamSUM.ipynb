{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oK_TzYwpd1LqlSQBx12p_j3JTVWrRSqB","timestamp":1670085949813},{"file_id":"1ahseFGDVwY8yEmegHemMCoQC2houCqpA","timestamp":1668264569189}],"collapsed_sections":["fZNKwHmTpjxX"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"2d4321bc9c2e4958bc8f2e9dd99d3e07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_52c8ae7f78204f96afa06661661b5bdd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b82ee21af65843a3b3f93a5a0206bc98","IPY_MODEL_e850dc51f2034920bc256fe68f0ca2c4","IPY_MODEL_1cbcdfcd87a143dbb4d3a6219384f95d"]}},"52c8ae7f78204f96afa06661661b5bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b82ee21af65843a3b3f93a5a0206bc98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d45731ddf8fb429880d33ca3a6158591","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5d816bb402c491db0d070e9684550f2"}},"e850dc51f2034920bc256fe68f0ca2c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_11aee89655e1448999f367f56efa1c9e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04172f3c501645cc91aa9f66299542a0"}},"1cbcdfcd87a143dbb4d3a6219384f95d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c30047debec3489bb965deb9e01ea53b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [00:00&lt;00:00, 84.64it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e82a1b009bfb42939b1acb5210f54d77"}},"d45731ddf8fb429880d33ca3a6158591":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e5d816bb402c491db0d070e9684550f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11aee89655e1448999f367f56efa1c9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04172f3c501645cc91aa9f66299542a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c30047debec3489bb965deb9e01ea53b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e82a1b009bfb42939b1acb5210f54d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc7239977be149b988459100db28fc5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8856f88c91b4115b45a300494b3251b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5383487c890d472ca63d2066fcd85264","IPY_MODEL_44b30c2a18464b9b8983b255d5b3eb1b","IPY_MODEL_97b0cdbf469b4684875a7ae00a9d9726"]}},"b8856f88c91b4115b45a300494b3251b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5383487c890d472ca63d2066fcd85264":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0b033bde7ec46138ab0fda4ba9c2694","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07faa3187a7340ee97f36fb7782977e0"}},"44b30c2a18464b9b8983b255d5b3eb1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60b4c05cabc844088aa2dd06f0f5e01c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_912c87135fd84c5689c2cb6a6813581b"}},"97b0cdbf469b4684875a7ae00a9d9726":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b54233200d5740c4b40d1bf4db6cba1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:01&lt;00:00,  1.01s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b477dd41b6c4a65b1b4de41fb069f1f"}},"c0b033bde7ec46138ab0fda4ba9c2694":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07faa3187a7340ee97f36fb7782977e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60b4c05cabc844088aa2dd06f0f5e01c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"912c87135fd84c5689c2cb6a6813581b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b54233200d5740c4b40d1bf4db6cba1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9b477dd41b6c4a65b1b4de41fb069f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"metadata":{"id":"gMzbM4naD2g9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install wandb\n","!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHu9oO2Vqiud","executionInfo":{"status":"ok","timestamp":1670094847636,"user_tz":300,"elapsed":6821,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"outputId":"5c434ed2-e943-45a7-c21a-2d6e79e69f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.11)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.29)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhiteshwarjmu\u001b[0m (\u001b[33makatsuki_leaf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["import wandb\n","\n","wandb.init(project=\"BART-Joint-SAMSum\", entity=\"akatsuki_leaf\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"xwFTxxJiqwvI","executionInfo":{"status":"ok","timestamp":1670094850546,"user_tz":300,"elapsed":2918,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"outputId":"07c13604-8784-44bd-eebf-809e56e047e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhiteshwarjmu\u001b[0m (\u001b[33makatsuki_leaf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/html":["Tracking run with wandb version 0.13.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20221203_191410-39u7hf6q</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/akatsuki_leaf/BART-Joint-SAMSum/runs/39u7hf6q\" target=\"_blank\">faithful-hill-4</a></strong> to <a href=\"https://wandb.ai/akatsuki_leaf/BART-Joint-SAMSum\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f6c1ca37e90>"],"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/akatsuki_leaf/BART-Joint-SAMSum/runs/39u7hf6q?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    \n","    print('Memory Usage:',round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On8STYHmSKtA","executionInfo":{"status":"ok","timestamp":1670094852221,"user_tz":300,"elapsed":1683,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"outputId":"f6eef30f-f50a-4fd6-cd25-b85f67e009b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","Tesla T4\n","Memory Usage: 14.8 GB\n","Allocated: 0.0 GB\n","Cached:    0.0 GB\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import random\n","\n","def set_random_seed(seed):\n","     torch.manual_seed(seed)\n","     torch.cuda.manual_seed_all(seed)\n","     np.random.seed(seed)\n","     random.seed(seed)\n","     torch.backends.cudnn.deterministic = True\n","set_random_seed(0)"],"metadata":{"id":"faaqh5xzw8pI"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOsHUjgdIrIW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af5d1756-1238-4d30-efaf-abd9b9d91120","executionInfo":{"status":"ok","timestamp":1670094856384,"user_tz":300,"elapsed":4170,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}}},"source":["! pip install datasets transformers rouge-score nltk py7zr"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.25.1)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: py7zr in /usr/local/lib/python3.7/dist-packages (0.20.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (3.10.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.0.0)\n","Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from py7zr) (3.16.0)\n","Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.7/dist-packages (from py7zr) (0.15.3)\n","Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from py7zr) (1.0.1)\n","Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from py7zr) (0.3.1)\n","Requirement already satisfied: texttable in /usr/local/lib/python3.7/dist-packages (from py7zr) (1.6.7)\n","Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.7/dist-packages (from py7zr) (1.0.9)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from py7zr) (5.4.8)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from py7zr) (0.2.3)\n","Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from py7zr) (1.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n"]}]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"e-v6Mjk_JvG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %cd /content/drive/MyDrive/NLP Project with SCL"],"metadata":{"id":"z5nOd8wBL-BO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["# Fine-tuning a model on a summarization task"]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","metadata":{"id":"IreSlFmlIrIm","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["2d4321bc9c2e4958bc8f2e9dd99d3e07","52c8ae7f78204f96afa06661661b5bdd","b82ee21af65843a3b3f93a5a0206bc98","e850dc51f2034920bc256fe68f0ca2c4","1cbcdfcd87a143dbb4d3a6219384f95d","d45731ddf8fb429880d33ca3a6158591","e5d816bb402c491db0d070e9684550f2","11aee89655e1448999f367f56efa1c9e","04172f3c501645cc91aa9f66299542a0","c30047debec3489bb965deb9e01ea53b","e82a1b009bfb42939b1acb5210f54d77"]},"outputId":"6016a592-abc4-4656-e0a0-58e13baff731","executionInfo":{"status":"ok","timestamp":1670094859524,"user_tz":300,"elapsed":3148,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}}},"source":["from datasets import load_dataset, load_metric\n","\n","raw_datasets = load_dataset(\"samsum\")\n","\n","metric = load_metric(\"rouge\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Found cached dataset samsum (/root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d4321bc9c2e4958bc8f2e9dd99d3e07","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  \"\"\"\n"]}]},{"cell_type":"markdown","source":["## BART"],"metadata":{"id":"Ql3_w39HR2zi"}},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["### Preprocessing the data"]},{"cell_type":"code","metadata":{"id":"TkXftRLYwOqc"},"source":["model_checkpoint = \"facebook/bart-base\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXNLu_-nIrJI"},"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_token_length(dataset):\n","    ids=[]\n","    for i in range(len(dataset['dialogue'])):\n","        if len(tokenizer(dataset['dialogue'][i])['input_ids'])>1000:\n","            ids.append(i)\n","    print(ids)\n","    return ids\n","def remove_idx(list_idx, dataset):\n","    return dataset.select((\n","          i for i in range(len(dataset)) \n","          if i not in set(list_idx)))\n","    \n","train_ids=check_token_length(raw_datasets['train'])\n","validation_ids=check_token_length(raw_datasets['validation'])\n","test_ids = check_token_length(raw_datasets['test'])\n","changed_datasets_train=remove_idx(train_ids, raw_datasets['train'])\n","changed_datasets_val = remove_idx(validation_ids, raw_datasets['validation'])\n","changed_datasets_test = remove_idx(test_ids, raw_datasets['test'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9hiJeaPFqEK","executionInfo":{"status":"ok","timestamp":1670095118205,"user_tz":300,"elapsed":254679,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"outputId":"fbc5b071-bd2a-47b2-e86f-00b0af1e69d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["[4269, 8198]\n","[]\n"]},{"output_type":"stream","name":"stderr","text":["Parameter 'indices'=<generator object remove_idx.<locals>.<genexpr> at 0x7f6a813f6250> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","metadata":{"id":"vc0BSBLIIrJQ"},"source":["max_input_length = 1024\n","max_target_length = 128\n","\n","def make_one_hot_sequence(input_ids, sequence_ids):\n","    changed_sequence_id=[0]\n","    token_to_speaker_id={}\n","    uniq_id = 1\n","    for dic in sequence_ids:\n","        if str(input_ids[dic['spk'][0]:dic['spk'][1]]) in token_to_speaker_id:\n","            speaker_id = token_to_speaker_id[str(input_ids[dic['spk'][0]:dic['spk'][1]])]\n","        else:\n","            token_to_speaker_id[str(input_ids[dic['spk'][0]:dic['spk'][1]])] = uniq_id\n","            speaker_id = uniq_id\n","            uniq_id+=1\n","        for _ in range(dic['spk'][0], dic['spk'][1]):\n","            changed_sequence_id.append(speaker_id)\n","        for _ in range(dic['utt'][0], dic['utt'][1]):\n","            changed_sequence_id.append(-1)\n","    changed_sequence_id.append(0)\n","    return changed_sequence_id \n","\n","\n","def preprocess_function(examples): ## hit gold here. change this preprocess function to include speaker and turn information. \n","    slash_n = tokenizer([\"\\r\\n\"])['input_ids'][0][1:-1]\n","    slash_n_mask = tokenizer([\"\\r\\n\"])['attention_mask'][0][1:-1]\n","    inputs_list=[]\n","    masks_list=[]\n","    pos_list=[]\n","    for index in range(len(examples['dialogue'])):\n","        # breaking the dialogue for spk:utt info\n","        broken=[]\n","        for utt in examples['dialogue'][index].split(\"\\r\\n\"):\n","            first_ind = utt.find(':')\n","            broken.append(utt[:first_ind])\n","            broken.append(utt[first_ind:])\n","        \n","        tokenized_broken = tokenizer(broken)['input_ids']\n","        attention_broken = tokenizer(broken)['attention_mask']\n","        \n","        # adding \\r\\n tokens\n","        for i in range(1, len(tokenized_broken)-1, 2):\n","            tokenized_broken[i].insert(-1, slash_n[0])\n","            tokenized_broken[i].insert(-1, slash_n[1])\n","            attention_broken[i].insert(-1, slash_n_mask[0])\n","            attention_broken[i].insert(-1, slash_n_mask[1])\n","        joined = tokenized_broken[0]\n","\n","        # annotating for spk_utt_pos\n","        assoc_dict={}\n","        assoc_dict['spk'] = [1, len(tokenized_broken[0])-1] # the range is actually exclusive of the last index. \n","        odd_bool = True\n","        running_length = len(tokenized_broken[0])\n","        sequence_ids=[]\n","        for inner in tokenized_broken[1:]:\n","            if odd_bool==True:\n","                assoc_dict['utt']=[running_length-1, running_length+len(inner)-3]\n","                odd_bool=False\n","                sequence_ids.append(assoc_dict)\n","                assoc_dict={}\n","            else:\n","                assoc_dict['spk']=[running_length-1, running_length+len(inner)-3]\n","                odd_bool=True\n","            joined = joined[:-1]+inner[1:]\n","            running_length += (len(inner)-2)\n","        \n","        # test for CUDA assert error\n","        if(len(joined)>1024):\n","            print(\"input tokens list length greater than 1024, skipping example\", end=' ')\n","            print(\"equal to\", len(joined))\n","            print(tokenizer.decode(joined))\n","        \n","        # creating inputs list\n","        inputs_list.append(joined)\n","        pos_list.append(make_one_hot_sequence(joined, sequence_ids))\n","        \n","        # creating new mask\n","        joined_mask = attention_broken[0]\n","        for inner_attention in attention_broken[1:]:\n","            joined_mask = joined_mask[:-1]+inner_attention[1:]\n","        masks_list.append(joined_mask)\n","    \n","    # overriding normal model_inputs\n","    inputs = [doc for doc in examples[\"dialogue\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    model_inputs['input_ids'] = inputs_list\n","    model_inputs['attention_mask'] = masks_list\n","    model_inputs['spk_utt_pos'] = pos_list\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDtsaJeVIrJT","executionInfo":{"status":"ok","timestamp":1670095119409,"user_tz":300,"elapsed":759,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["cc7239977be149b988459100db28fc5f","b8856f88c91b4115b45a300494b3251b","5383487c890d472ca63d2066fcd85264","44b30c2a18464b9b8983b255d5b3eb1b","97b0cdbf469b4684875a7ae00a9d9726","c0b033bde7ec46138ab0fda4ba9c2694","07faa3187a7340ee97f36fb7782977e0","60b4c05cabc844088aa2dd06f0f5e01c","912c87135fd84c5689c2cb6a6813581b","b54233200d5740c4b40d1bf4db6cba1c","9b477dd41b6c4a65b1b4de41fb069f1f"]},"outputId":"7a0c6939-2e0e-4e28-8e65-e0942589fdd9"},"source":["tokenized_datasets_train_o = changed_datasets_train.map(preprocess_function, batched=True)\n","tokenized_datasets_val_o = changed_datasets_val.map(preprocess_function, batched=True)\n","tokenized_datasets_test_o = changed_datasets_test.map(preprocess_function, batched=True)\n","\n","# tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n","tokenized_datasets_train = tokenized_datasets_train_o.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_datasets_val = tokenized_datasets_val_o.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_datasets_test = tokenized_datasets_test_o.remove_columns(['id', 'dialogue', 'summary'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-af3edf4ad62c7168.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e/cache-9650456eeb2f172d.arrow\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc7239977be149b988459100db28fc5f","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3579: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"]}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","from transformers.modeling_utils import unwrap_model\n","from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n","\n","\n","class CustomTrainer(Seq2SeqTrainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # How the loss is computed by Trainer. By default, all models return the loss in the first element.\n","        # Subclass and override for custom behavior.\n","        # print(inputs)\n","        if self.label_smoother is not None and \"labels\" in inputs:\n","            labels = inputs.pop(\"labels\")\n","        else:\n","            labels = None\n","        outputs = model(**inputs)\n","\n","        # Save past state if it exists\n","        # TODO: this needs to be fixed and mselfade cleaner later.\n","\n","        if self.args.past_index >= 0:\n","            self._past = outputs[self.args.past_index]\n","\n","        if labels is not None:\n","            if unwrap_model(model)._get_name() in MODEL_FOR_CAUSAL_LM_MAPPING_NAMES.values():\n","                loss = self.label_smoother(outputs, labels, shift_labels=True)\n","            else:\n","                loss = self.label_smoother(outputs, labels)\n","        else:\n","            if isinstance(outputs, dict) and \"loss\" not in outputs:\n","                raise ValueError(\n","                    \"The model did not return a loss from the inputs, only the following keys: \"\n","                    f\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\n","                )\n","            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n","            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n","        return (loss, outputs) if return_outputs else loss\n"],"metadata":{"id":"eXTmGGJbtFhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import PreTrainedTokenizerBase\n","from transformers.utils import PaddingStrategy\n","from transformers import DataCollatorForSeq2Seq\n","from typing import Optional, Any, Union\n","import numpy as np\n","\n","\n","class CustomCollatorForSeq2Seq(DataCollatorForSeq2Seq):\n","    r\"\"\"\n","    Data collator that will dynamically pad the inputs received, as well as the labels.\n","    Args:\n","        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n","            The tokenizer used for encoding the data.\n","        model ([`PreTrainedModel`]):\n","            The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n","            prepare the *decoder_input_ids*\n","            This is useful when using *label_smoothing* to avoid calculating loss twice.\n","        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n","            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n","            among:\n","            - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single sequence\n","              is provided).\n","            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n","              acceptable input length for the model if that argument is not provided.\n","            - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n","              lengths).\n","        max_length (`int`, *optional*):\n","            Maximum length of the returned list and optionally padding length (see above).\n","        pad_to_multiple_of (`int`, *optional*):\n","            If set will pad the sequence to a multiple of the provided value.\n","            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n","            7.5 (Volta).\n","        label_pad_token_id (`int`, *optional*, defaults to -100):\n","            The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n","        return_tensors (`str`):\n","            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n","    \"\"\"\n","\n","    tokenizer: PreTrainedTokenizerBase\n","    model: Optional[Any] = None\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    label_pad_token_id: int = -100\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features, return_tensors=None):\n","        if return_tensors is None:\n","            return_tensors = self.return_tensors\n","        labels = [feature[\"labels\"] for feature in features] if \"labels\" in features[0].keys() else None\n","        # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n","        # same length to return tensors.\n","        if labels is not None:\n","            max_label_length = max(len(l) for l in labels)\n","            if self.pad_to_multiple_of is not None:\n","                max_label_length = (\n","                        (max_label_length + self.pad_to_multiple_of - 1)\n","                        // self.pad_to_multiple_of\n","                        * self.pad_to_multiple_of\n","                )\n","\n","            padding_side = self.tokenizer.padding_side\n","            for feature in features:\n","                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n","                if isinstance(feature[\"labels\"], list):\n","                    feature[\"labels\"] = (\n","                        feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n","                    )\n","                elif padding_side == \"right\":\n","                    feature[\"labels\"] = np.concatenate([feature[\"labels\"], remainder]).astype(np.int64)\n","                else:\n","                    feature[\"labels\"] = np.concatenate([remainder, feature[\"labels\"]]).astype(np.int64)\n","        # added here\n","        spk_utt_pos = [feature[\"spk_utt_pos\"] for feature in features]\n","        max_spk_utt_pos_length = max(len(l) for l in spk_utt_pos)\n","\n","        if self.pad_to_multiple_of is not None:\n","            max_spk_utt_pos_length = (\n","                    (max_spk_utt_pos_length + self.pad_to_multiple_of - 1)\n","                    // self.pad_to_multiple_of\n","                    * self.pad_to_multiple_of\n","            )\n","\n","        padding_side = self.tokenizer.padding_side\n","        for feature in features:\n","            remainder = [0] * (max_spk_utt_pos_length - len(feature[\"spk_utt_pos\"]))\n","            if isinstance(feature[\"spk_utt_pos\"], list):\n","                feature[\"spk_utt_pos\"] = (\n","                    feature[\"spk_utt_pos\"] + remainder if padding_side == \"right\" else remainder + feature[\n","                        \"spk_utt_pos\"]\n","                )\n","            elif padding_side == \"right\":\n","                feature[\"spk_utt_pos\"] = np.concatenate([feature[\"spk_utt_pos\"], remainder]).astype(np.int64)\n","            else:\n","                feature[\"spk_utt_pos\"] = np.concatenate([remainder, feature[\"spk_utt_pos\"]]).astype(np.int64)\n","\n","        features = self.tokenizer.pad(\n","            features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=return_tensors,\n","        )\n","\n","        # prepare decoder_input_ids\n","        if (\n","                labels is not None\n","                and self.model is not None\n","                and hasattr(self.model, \"prepare_decoder_input_ids_from_labels\")\n","        ):\n","            decoder_input_ids = self.model.prepare_decoder_input_ids_from_labels(labels=features[\"labels\"])\n","            features[\"decoder_input_ids\"] = decoder_input_ids\n","\n","        return features\n"],"metadata":{"id":"HEZHf93mtTx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","from transformers import BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers.modeling_utils import unwrap_model\n","from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n","\n","from transformers.models.bart.modeling_bart import BartConfig\n","import torch\n","from typing import *\n","from transformers.modeling_outputs import Seq2SeqLMOutput\n","from transformers.models.bart.modeling_bart import shift_tokens_right\n","import random\n","from tqdm import tqdm\n","import gc\n","import itertools\n","\n","class BartWithSCL(BartForConditionalGeneration):\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","\n","    def set_losses_list(self, SCLossesList=['token']):\n","\n","        self.SCLossesList = SCLossesList\n","    def set_scl_coeff(self, scl_coeff=1e-1):\n","        self.scl_coeff=scl_coeff\n","    def token_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Token Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        wandb.config = {\n","          \"epochs\": 100,\n","          \"m_lambda\": 100\n","        }\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        spk_utt_states[spk].append(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]])\n","            \n","            \n","            #---------- hitesh------------------------------\n","            # positive samples\n","            # L_pos = 0\n","            # L_neg = 0 \n","\n","            # sampled_spk_utt_states = []           \n","\n","            # for spk in uniq_spks:\n","            #     utts = len(spk_utt_states[spk])\n","            #     spk_utt = []\n","            #     if utts > 1:\n","            #         # ids = random.sample(list(range(len(spk_utt_states[spk]))), random.randint(1, utts))\n","            #         ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","            #         for i in ids:\n","            #           spk_utt.append(spk_utt_states[spk][i])\n","            #     sampled_spk_utt_states.append(spk_utt)\n","\n","            # for instance in sampled_spk_utt_states:\n","            #   for i in range(len(instance)):\n","            #     for j in range(len(instance)):\n","            #       mat_mul = torch.einsum('ij, kj->ik', instance[i], instance[j])\n","            #       sigm = torch.sigmoid(mat_mul)\n","            #       log = torch.log(sigm)\n","            #       L_pos += torch.sum(-1 * log)\n","            # # print(\"L_pos\", L_pos)\n","\n","            # #negative loss\n","            # for i in range(0,len(sampled_spk_utt_states)):\n","            #   instance = sampled_spk_utt_states[i]\n","\n","            #   neg_instances = sampled_spk_utt_states[:i]+sampled_spk_utt_states[i+1:]\n","            #   neg_instances = list(itertools.chain(*neg_instances))\n","            #   # neg_instances = random.choices(neg_instances,k = random.randint(1, len(neg_instances)))\n","            #   if len(neg_instances)>0:\n","            #     # print(len(neg_instances))\n","            #     # print(\"-------------------------\")\n","            #     # print(sampled_spk_utt_states)\n","            #     neg_instances = random.choices(neg_instances,k = 2)\n","            #     for i in range(len(instance)):\n","            #       for j in range(len(neg_instances)):\n","            #         mat_mul = torch.einsum('ij, kj->ik', instance[i], neg_instances[j])\n","            #         sigm = torch.sigmoid(mat_mul)\n","            #         log = torch.log(1 - sigm+1e-5)\n","            #         L_neg += torch.sum(-1 * log)\n","            #---------- hitesh------------------------------\n","            \n","            \n","            # positive samples\n","            L_pos = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","                    id1 = ids[0]\n","                    id2 = ids[1]\n","                    mat_mul = torch.einsum('ij, kj->ik', spk_utt_states[spk][id1], spk_utt_states[spk][id1])\n","                    sigm = torch.sigmoid(mat_mul)\n","                    log = torch.log(sigm)\n","                    L_pos += torch.sum(-1 * log)\n","                    L_pos = torch.nan_to_num(L_pos, posinf = 1e10, neginf = -1e10)\n","            # print(\"L_pos\", L_pos)\n","            # negative samples\n","            \n","            L_neg = 0\n","            for spk in uniq_spks:\n","                new_uniq_spks = uniq_spks.copy()\n","                new_uniq_spks.remove(spk)\n","\n","                spk2 = random.choice(new_uniq_spks)\n","\n","                id1 = random.randint(0, len(spk_utt_states[spk])-1)\n","                id2 = random.randint(0, len(spk_utt_states[spk2])-1)\n","\n","                mat_mul = torch.einsum('ij, kj->ik', spk_utt_states[spk][id1], spk_utt_states[spk2][id2])\n","                sigm = torch.sigmoid(mat_mul)\n","                # print(1 - sigm)\n","                # print(1 - sigm+1e-5)\n","                log = torch.log(1 - sigm+1e-5)\n","                L_neg += torch.sum(-1 * log)\n","                \n","                L_neg = torch.nan_to_num(L_neg, posinf = 1e10, neginf = -1e10)\n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-token\", batch_scl})\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","    \n","    def turn_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Turn Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        mean_pool = torch.mean(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]], 0)\n","                        spk_utt_states[spk].append(mean_pool)\n","\n","            # positive samples\n","            L_pos = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.sample(list(range(len(spk_utt_states[spk]))), 2)\n","                    id1 = ids[0]\n","                    id2 = ids[1]\n","                    mat_mul = torch.einsum('i, j->', spk_utt_states[spk][id1], spk_utt_states[spk][id1])\n","                    sigm = torch.sigmoid(mat_mul)\n","                    log = torch.log(sigm)\n","                    L_pos += torch.sum(-1 * log)\n","                    # L_pos = torch.nan_to_num(L_pos, posinf = 1e10, neginf = -1e10)\n","            # print(\"L_pos\", L_pos)\n","            # negative samples\n","            L_neg = 0\n","            for spk in uniq_spks:\n","                new_uniq_spks = uniq_spks.copy()\n","                new_uniq_spks.remove(spk)\n","\n","                spk2 = random.choice(new_uniq_spks)\n","\n","                id1 = random.randint(0, len(spk_utt_states[spk])-1)\n","                id2 = random.randint(0, len(spk_utt_states[spk2])-1)\n","\n","                mat_mul = torch.einsum('i, j->', spk_utt_states[spk][id1], spk_utt_states[spk2][id2])\n","                sigm = torch.sigmoid(mat_mul)\n","                # print(1 - sigm)\n","                # print(1 - sigm+1e-5)\n","                log = torch.log(1 - sigm+1e-5)\n","                L_neg += torch.sum(-1 * log)\n","                \n","                # L_neg = torch.nan_to_num(L_neg, posinf = 1e10, neginf = -1e10)\n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-turn\", batch_scl})\n","\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","    \n","    def global_scl(self,\n","                  last_hidden_state: torch.FloatTensor,\n","                  spk_utt_pos: torch.LongTensor,\n","    ) -> torch.FloatTensor:\n","        r\"\"\"\n","        last_hidden_state (torch.LongTensor) of shape (batch_size, sequence_length, n_dims):\n","            Output of the last layer of the encoder.\n","        spk_utt_pos (torch.LongTensor) of shape (batch_size, sequence_length,):\n","            metadata about the speaker tokens and utterance tokens\n","        Returns:\n","        Turn Level Supervised Constrastive Loss (torch.LongTensor)\n","        \"\"\"\n","        batch_scl = 0\n","        for i in range(len(spk_utt_pos)):\n","            batch_element = spk_utt_pos[i]\n","            spk_utt_list = []\n","            spk_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            utt_dict = {'start': 0, 'end': 0, 'spk_id': 0, 'bool': False}\n","            for j in range(len(batch_element)):\n","                if batch_element[j] == 0 and j > 0:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                         'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    break\n","                if batch_element[j] > 0 and spk_dict['bool'] == False:\n","                    utt_dict['end'] = j\n","                    utt_dict['bool'] = False\n","                    if j > 1:\n","                        spk_utt_list.append({'spk': [spk_dict['start'], spk_dict['end'], spk_dict['spk_id']],\n","                                             'utt': [utt_dict['start'], utt_dict['end'], utt_dict['spk_id']]})\n","                    spk_dict['start'] = j\n","                    spk_dict['bool'] = True\n","                    spk_dict['spk_id'] = batch_element[j]\n","                    \n","\n","                if batch_element[j] < 0 and spk_dict['bool'] == True:\n","                    spk_dict['end'] = j\n","                    spk_dict['bool'] = False\n","                    utt_dict['spk_id'] = spk_dict['spk_id']\n","                    utt_dict['start'] = j\n","                    utt_dict['bool'] = True\n","            # uniq spks\n","            if spk_utt_list[0]['spk'][2]==0:\n","                continue\n","            uniq_spks = list(set([int(dic['spk'][2].cpu()) for dic in spk_utt_list]))\n","            if len(uniq_spks)==1:\n","                continue\n","            # spk_utt_states\n","            spk_utt_states = {spk: [] for spk in uniq_spks}\n","\n","            for spk in uniq_spks:\n","                for dic in spk_utt_list:\n","                    if spk == dic['utt'][2]:\n","                        mean_pool = torch.mean(last_hidden_state[i, dic['utt'][0]:dic['utt'][1]], 0)\n","                        spk_utt_states[spk].append(mean_pool)\n","\n","            # positive samples\n","            L_pos = 0\n","            L_neg = 0\n","            for spk in uniq_spks:\n","                if len(spk_utt_states[spk]) > 1:\n","                    ids = random.choice(list(range(len(spk_utt_states[spk]))))\n","                    \n","                    spk_mean_exc = torch.mean(torch.vstack([spk_utt_states[spk][temp] for temp in range(len(spk_utt_states[spk])) if temp != ids]), 0)\n","                    \n","                    pos_mat_mul = torch.einsum('i, j->', spk_utt_states[spk][ids], spk_mean_exc)\n","                    pos_sigm = torch.sigmoid(pos_mat_mul)\n","                    pos_log = torch.log(pos_sigm)\n","                    L_pos += torch.sum(-1 * pos_log)\n","\n","                    # negative sample\n","\n","                    new_uniq_spks = uniq_spks.copy()\n","                    new_uniq_spks.remove(spk)\n","                    \n","                    spk2 = random.choice(new_uniq_spks)\n","                    id_neg = random.choice(list(range(len(spk_utt_states[spk2]))))\n","                    neg_mat_mul = torch.einsum('i, j->', spk_utt_states[spk2][id_neg], spk_mean_exc)\n","                    neg_sigm = torch.sigmoid(neg_mat_mul)\n","                    neg_log = torch.log(1 - neg_sigm+1e-5)\n","                    L_neg += torch.sum(-1 * neg_log)\n","                \n","\n","            # print(\"L_neg\", L_neg)\n","            \n","            batch_scl += L_pos\n","            batch_scl += L_neg\n","            # wand.log({\"batch-scl-global\", batch_scl})\n","\n","        batch_scl /= last_hidden_state.size(0)\n","        gc.collect()\n","        return batch_scl\n","\n","    def forward(\n","            self,\n","            input_ids: torch.LongTensor = None,\n","            attention_mask: Optional[torch.Tensor] = None,\n","            spk_utt_pos: Optional[torch.Tensor] = None, ##changed here\n","            decoder_input_ids: Optional[torch.LongTensor] = None,\n","            decoder_attention_mask: Optional[torch.LongTensor] = None,\n","            head_mask: Optional[torch.Tensor] = None,\n","            decoder_head_mask: Optional[torch.Tensor] = None,\n","            cross_attn_head_mask: Optional[torch.Tensor] = None,\n","            encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n","            past_key_values: Optional[List[torch.FloatTensor]] = None,\n","            inputs_embeds: Optional[torch.FloatTensor] = None,\n","            decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n","            labels: Optional[torch.LongTensor] = None,\n","            use_cache: Optional[bool] = None,\n","            output_attentions: Optional[bool] = None,\n","            output_hidden_states: Optional[bool] = None,\n","            return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple, Seq2SeqLMOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n","            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n","            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n","        Returns:\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if labels is not None:\n","            if use_cache:\n","                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n","            use_cache = False\n","            if decoder_input_ids is None and decoder_inputs_embeds is None:\n","                decoder_input_ids = shift_tokens_right(\n","                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n","                )\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            encoder_outputs=encoder_outputs,\n","            decoder_attention_mask=decoder_attention_mask,\n","            head_mask=head_mask,\n","            decoder_head_mask=decoder_head_mask,\n","            cross_attn_head_mask=cross_attn_head_mask,\n","            past_key_values=past_key_values,\n","            inputs_embeds=inputs_embeds,\n","            decoder_inputs_embeds=decoder_inputs_embeds,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        if encoder_outputs is None:\n","            encoder = self.get_encoder()\n","            # TODO: mask the speaker names from the input IDs using the speaker pos info\n","            turn_attention_mask=None\n","            token_encoder_outputs=None\n","            tog_encoder_outputs=None\n","            \n","            if 'token' in self.SCLossesList:\n","                token_encoder_outputs = encoder(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    head_mask=head_mask,\n","                    inputs_embeds=inputs_embeds,\n","                    output_attentions=output_attentions,\n","                    output_hidden_states=output_hidden_states,\n","                    return_dict=return_dict,\n","                )\n","\n","            if 'turn' in self.SCLossesList or 'global' in self.SCLossesList:\n","                tog_attention_mask = torch.where(spk_utt_pos>0, 0, attention_mask)\n","                tog_encoder_outputs = encoder(\n","                    input_ids=input_ids,\n","                    attention_mask=tog_attention_mask,\n","                    head_mask=head_mask,\n","                    inputs_embeds=inputs_embeds,\n","                    output_attentions=output_attentions,\n","                    output_hidden_states=output_hidden_states,\n","                    return_dict=return_dict,\n","                )\n","        # if 'hidden_states' in encoder_outputs:\n","        #     print(\"encoder_outputs['last_hidden_state'].size(), encoder_outputs['hidden_states'].size()\",\n","        #     encoder_outputs['last_hidden_state'].size(), encoder_outputs['hidden_states'].size())\n","        # else:\n","        #     print(\"encoder_outputs['last_hidden_state'].size()\", encoder_outputs['last_hidden_state'].size())\n","\n","        lm_logits = self.lm_head(outputs[0])\n","        lm_logits = lm_logits + self.final_logits_bias.to(lm_logits.device)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = torch.nn.CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n","        # added here\n","        sc_loss = 0\n","        if 'token' in self.SCLossesList and labels is not None:\n","            sc_loss += self.token_scl(last_hidden_state=token_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","            # print(sc_loss)\n","        if 'turn' in self.SCLossesList and labels is not None:\n","            sc_loss += self.turn_scl(last_hidden_state=tog_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","        \n","        if 'global' in self.SCLossesList and labels is not None:\n","            sc_loss += self.global_scl(last_hidden_state=tog_encoder_outputs['last_hidden_state'], spk_utt_pos=spk_utt_pos)\n","        \n","        if not return_dict:\n","            output = (lm_logits,) + outputs[1:]\n","            return ((masked_lm_loss+(self.scl_coeff*sc_loss),) + output) if masked_lm_loss is not None else output\n","        loss = None\n","        if masked_lm_loss is None:\n","            loss = None\n","        else:\n","            loss = masked_lm_loss+(self.scl_coeff*sc_loss)\n","        return Seq2SeqLMOutput(\n","            loss=loss,\n","            logits=lm_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            cross_attentions=outputs.cross_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n"],"metadata":{"id":"nEvSIc03tW7d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV"},"source":["### Fine-tuning the model"]},{"cell_type":"code","metadata":{"id":"TlqNaB8jIrJW"},"source":["# from models import BartWithSCL\n","# from datacollator import CustomCollatorForSeq2Seq\n","# from trainer import CustomTrainer\n","\n","\n","from transformers import BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers.modeling_utils import unwrap_model\n","from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BartWithSCL.from_pretrained(model_checkpoint)\n","model.set_losses_list(['token','turn','global'])\n","model.set_scl_coeff(0.1)"],"metadata":{"id":"Khz2QvEoBYcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bliy8zgjIrJY"},"source":["batch_size = 3\n","args = Seq2SeqTrainingArguments(\n","    \"bart-tjoin-b6c0.1\",\n","    evaluation_strategy = \"epoch\",\n","    # eval_steps=5,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=2,\n","    weight_decay=0.01,\n","    # save_total_limit=2,\n","    num_train_epochs=5,\n","    logging_steps = 10, ## added\n","    predict_with_generate=True,\n","    remove_unused_columns=False, ## added\n","    fp16=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = CustomCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"fhYv33h74na-"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmvbnJ9JIrJd"},"source":["import nltk\n","import numpy as np\n","import torch\n","torch.cuda.empty_cache()\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    for i in range(0,50):\n","      # print(tokenized_datasets_val[\"dialogue\"][i])\n","      print(\"-----------\",i,\"--------------\")\n","      print(\"------>Predictions by Model\")\n","      print(decoded_preds[i])\n","      print(\"----->Predictions Original\")\n","      print(decoded_labels[i])\n","      print(\"**************************\")\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"imY1oC3SIrJf","executionInfo":{"status":"ok","timestamp":1670095128215,"user_tz":300,"elapsed":4590,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f76b8776-142f-4bdd-e5f0-da6a82b044e8"},"source":["trainer = CustomTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets_train,\n","    eval_dataset=tokenized_datasets_val,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cuda_amp half precision backend\n"]}]},{"cell_type":"code","metadata":{"id":"2xixI4gdbuoe","executionInfo":{"status":"ok","timestamp":1670095128216,"user_tz":300,"elapsed":27,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2222231-b697-49c1-ae7e-8bc87066ac6e"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"5ruUnR4V7-Li","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8b7c9cba-b63b-461b-df82-e169171911db","executionInfo":{"status":"ok","timestamp":1670118908291,"user_tz":300,"elapsed":6912261,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}}},"execution_count":25,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 14730\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 6\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 12275\n","  Number of trainable parameters = 139420416\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8790' max='12275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 8790/12275 4:41:04 < 1:51:28, 0.52 it/s, Epoch 3.58/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.450500</td>\n","      <td>8.107692</td>\n","      <td>44.439600</td>\n","      <td>20.240400</td>\n","      <td>36.597900</td>\n","      <td>40.565500</td>\n","      <td>17.968200</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>11.862200</td>\n","      <td>8.521297</td>\n","      <td>46.382100</td>\n","      <td>22.914800</td>\n","      <td>39.131300</td>\n","      <td>42.485000</td>\n","      <td>17.328900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>9.983500</td>\n","      <td>5.713129</td>\n","      <td>46.435500</td>\n","      <td>23.397000</td>\n","      <td>39.408800</td>\n","      <td>42.753800</td>\n","      <td>17.438900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-1000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-1000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-1500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-1500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-2000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-2000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-2000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["----------- 0 --------------\n","------>Predictions by Model\n","A's son wants to get a puppy for his son.\n","He wants to go to\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma has just fallen in love with the advent calendar.\n","Rob and Lauren are going\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant.\n","Jackie is worried about it, but she doesn't want to talk\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","Kiki and Marla\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert has to buy guitar cable at a music shop.\n","Fred will catch it on google\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith has run out of cereals.\n","Megan will check in the drawer next to the\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Evelyn a video.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Marion invited Theresa to Tom's new place for a dinner.\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane wants to make a reservation for 6 people tonight around 20:00 at 21:\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","Tina and Nancy laugh at her accent.\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Barbara got a coconut milk one from Haylee.\n","She put it next to eggs\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy are waiting for the tour.\n","They are going to the register now\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Lidia are going to the Jandia Peninsula tomorrow.\n","Cecil\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Nickola has found Sophie's pockets and handbags.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay and she is looking for a b-movie.\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James has a dream to become a voice actor.\n","He has already worked in radio.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy has errands to run.\n","Alice will join him at Nick's at 5\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will be before 12.\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Matteo doesn't like Gosia because she likes football and video games.\n","Gi\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Jannette is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer and Alois are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will be back in a few minutes.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny picture of Chad.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Sadie needs to go to the dentist quickly after work.\n","Chloe will pick it up\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Carter and Olivia are planning to launch a new restaurant next month.\n","Olivia is interested in\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine is back from surgery.\n","She has to reschedule her surgery tomorrow.\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey cheated on Olivia with numerous girls.\n","He got some chick pregnant 2 days ago\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda is proud of her dancing classes with Michael.\n","Chris and Amanda are going to\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Taylor has a question about Isabel's bf.\n","Isabel hasn't had any.\n","Taylor\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Theo is thinking about the Italian Alpes on Friday.\n","Toby will pick him up\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Clara hasn't called to tell Phil that Brandon is late.\n","Phil will prepare a\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again.\n","Olga will reschedule.\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Diane's kids are Lorelai and Kate's.\n","Kate will let her know\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew has a cold.\n","He has to call in sick.\n","Daniel will drop by after\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","Alex and Sam are watching \"Millionaires\" on tv.\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Angelica has the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Sophie is waiting for a client.\n","Gwen will let Sophie know in 15\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel is on his way to Sue's in a few minutes.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some squash.\n","George will pan fry the\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken started running and wanted to track his progress, but his battery was almost depleted.\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann hasn't been at Ivan's birthday party yet.\n","Ivan has bought her something for\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Delilah wants Rowan to take a look at Ashley's fb page.\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj has a breakthrough with his wife's papers.\n","Magda doesn't\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Ann and Peter are meeting at the 3rd floor hotel.\n","They are going to have\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate and Terry are going to the Museum of the city of NY at 2.30\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at her house at 10 tonight.\n","Broke will pick them\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica and Bradley are going to Bradley's birthday party tomorrow at 8pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla needs to check if she has received the money.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-2500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-2500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-2500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-3000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-3000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-3000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-3500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-3500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-3500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-4000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-4000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-4000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-4500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-4500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-4500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["----------- 0 --------------\n","------>Predictions by Model\n","A wants to get a puppy for her son.\n","She will take him to the animal\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma wants to buy an advent calendar for her kids.\n","Rob and Lauren like the\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant.\n","She doesn't want to talk about it because she's worried about\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert has to buy guitar cable.\n","Fred gives him the address of the music shop.\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith and Megan are running out of milk and cereals.\n","Megan checked in the drawer\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Evelyn a video.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Theresa, Luis and Adam are going to Tom's new place.\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane will make a reservation for 6 people tonight around 20:00.\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","She's going travelling with 3 other Brit\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Barbara got the coconut milk one for Haylee.\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy need to hurry to catch the tour.\n","Wendy is at the register\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Cecil are going to the Jandia Peninsula tomorrow after dinner.\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Nickola has found Sophie's pockets and handbags.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay about bad movies as her topic.\n","Dennis recommends \"\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James has a dream to become a voice actor.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy can't think any more today because she had errands to run.\n","She\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will open the door.\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Giuseppe doesn't like games.\n","Matteo likes Gosia.\n","Giuseppe\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Mom is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer, Alois and Hilegard are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will be in a few minutes to finish the article.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny photo.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Sadie needs to go to the dentist on Thursday after work.\n","Chloe will pick up\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Olivia wants to launch a new restaurant in the city centre next month.\n","Carter\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine's back from surgery.\n","Guy will come to the hospital to check on her\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey and Olivia broke up 2 days ago.\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda went to dance classes yesterday.\n","The instructor needed a partner to show the steps\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Taylor's friends' daughters bring their bfs to her.\n","Isabel hasn't had any\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Toby and Theo are leaving on Friday.\n","Toby will come back by train to Tor\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Brandon will be late, because he called to say he'd be late.\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again.\n","She cancelled last time because she didn't want to catch\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Diane and Kate are going to name their children Lorelai.\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew had to call in sick because he had a cold.\n","Daniel will drop by after\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","John, Alex and Sam are watching 'Millionaires' on tv.\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Angelica has the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Sophie is waiting for a client at the restaurant.\n","Gwen will let Sophie\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel will come downstairs in a few minutes.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some squash for George.\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken started running and wanted to track his progress.\n","Martha installed endomondo.\n","Ken\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann didn't come to Ivan's birthday party.\n","Ivan bought her something for her birthday\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Rowan has some important stuff to do on Facebook.\n","Delilah sends Rowan\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj got the letter from the government that his wife's papers won't\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Maria, Ann and Peter are at the hotel.\n","They will have lunch together.\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate and Terry are going to the Museum of the city of NY at 2-2\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at Brooke's house.\n","She will come round at 10 tonight\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica will come to Bradley's birthday party tomorrow at 8 pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla got 250 from Adrian.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-5000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-5000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-5000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-5500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-5500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-5500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-6000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-6000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-6000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-6500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-6500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-6500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-7000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-7000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-7000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["----------- 0 --------------\n","------>Predictions by Model\n","A wants to get a puppy for her son.\n","She will take him to the animal\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma wants to buy an advent calendar for her kids.\n","Rob likes it.\n","Lauren\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant.\n","She doesn't want to talk about it because she's worried about\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert has to buy guitar cable.\n","Fred gives him the address of the music shop.\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith will buy some milk and cereals.\n","Megan will check in the drawer next to\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Holly a video of herself and Evelyn.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Theresa, Luis and Adam are at Tom's new place.\n","Marion invited them\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane will make a reservation for 6 people tonight around 20:00.\n","There is no\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","She has been in Cardiff for 21 years\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Haylee is in dairy section and can't find the coconut milk one she wanted.\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy need to hurry to catch the tour.\n","Wendy is at the register\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Cecil went to the Jandia Peninsula.\n","Cecil wants to explore\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Sophie has found Nickola's pockets and handbags twice already.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay about bad movies.\n","She will cover \"The Room\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James has a dream to become a voice actor.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy and Alice are going for drinks after work.\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will open the door and Caron will\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Giuseppe is dating Gosia.\n","Giuseppe doesn't like games either.\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Mom is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer and Hildegard are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will get back to Madison in a few minutes.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny photo.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Sadie needs to go to the dentist on Thursday.\n","Chloe will pick up Sadie\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Olivia is launching a new restaurant in the city centre next month.\n","Carter is\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine is worried about Kenny.\n","He's back from surgery, but the doctors don\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey and Olivia broke up 2 days ago.\n","Olivia cheated on her with numerous girls\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda went to dance classes yesterday.\n","The instructor needed a partner to show the steps\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Isabel hasn't introduced Taylor to her bf yet.\n","Taylor will bring him.\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Theo is leaving on Friday.\n","Toby will come back by train on Monday.\n","Toby\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Brandon will be late.\n","Clara will prepare a report on the absenteeism and lateness\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again.\n","She cancelled last time.\n","Olga will reschedule\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Kate will be Diane's daughter Lorelai.\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew had to call in sick because of a cold.\n","Daniel will drop by after work\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","Alex and Sam are watching 'Millionaires' on tv.\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Jessica and Angelica have the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Gwen and Sophie will meet at the restaurant in 15 minutes.\n","Dee is waiting for\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel is on his way to meet Sue.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some salmon and shaving cream.\n","George will\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken used endomondo for running.\n","It doesn't work properly.\n","Ken was running\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann couldn't come to Ivan's birthday party.\n","Ivan bought her something for her birthday\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Rowan has some important stuff to do.\n","Delilah sent Rowan a photo\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj got the letter with the working permission from the government.\n","Magda\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Maria is on her way to the hotel.\n","Peter is still at the convention.\n","Ann\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate and Terry are going to the Museum of the city of NY around 2-2\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at Brooke's house.\n","She will come round at 10 tonight\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica will come to Bradley's birthday party tomorrow at 8 pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla received the money in 250 days.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-7500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-7500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-7500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-8000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-8000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-8000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-8500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-8500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-8500/special_tokens_map.json\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12275' max='12275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12275/12275 6:36:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.450500</td>\n","      <td>8.107692</td>\n","      <td>44.439600</td>\n","      <td>20.240400</td>\n","      <td>36.597900</td>\n","      <td>40.565500</td>\n","      <td>17.968200</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>11.862200</td>\n","      <td>8.521297</td>\n","      <td>46.382100</td>\n","      <td>22.914800</td>\n","      <td>39.131300</td>\n","      <td>42.485000</td>\n","      <td>17.328900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>9.983500</td>\n","      <td>5.713129</td>\n","      <td>46.435500</td>\n","      <td>23.397000</td>\n","      <td>39.408800</td>\n","      <td>42.753800</td>\n","      <td>17.438900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.524500</td>\n","      <td>5.311158</td>\n","      <td>47.504300</td>\n","      <td>24.479600</td>\n","      <td>40.303000</td>\n","      <td>43.734400</td>\n","      <td>17.740800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>11.878200</td>\n","      <td>5.969446</td>\n","      <td>47.430400</td>\n","      <td>24.384600</td>\n","      <td>40.395400</td>\n","      <td>43.797900</td>\n","      <td>17.920500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-9000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-9000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-9000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-9500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-9500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-9500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"output_type":"stream","name":"stdout","text":["----------- 0 --------------\n","------>Predictions by Model\n","A wants to get a puppy for her son.\n","She will take him to the animal\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma wants to buy an advent calendar for her kids.\n","Rob, Lauren and Rob\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant with Patricia Stevens.\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert needs to buy guitar cable.\n","Fred gives him the address of the music shop.\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith will buy some milk and cereals and Megan will check in the drawer next to\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Evelyn a video of herself making noise.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Marion and Adam are going to Tom's new place for a dinner.\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane will make a reservation for 6 people tonight around 20:00.\n","There is no\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","She has a Texan drawl.\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Haylee is in dairy section.\n","She can't find the coconut milk one she wanted\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy need to hurry to catch the tour.\n","Wendy is at the register\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Cecil are going to the Jandia Peninsula.\n","Cecil is driving\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Sophie has checked pockets and handbags twice already.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay about bad movies as her topic.\n","She will also\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James's biggest dream is to become a voice actor.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy and Alice are going for drinks after work.\n","They are going to meet Fred\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will open the door.\n","Caron will\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Giuseppe is dating Gosia.\n","Giuseppe doesn't like games either.\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Mom is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer, Alois and Hildegard are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will be through with the article in a few minutes.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny photo.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Chloe will borrow Sadie's bike on Wednesday evening.\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Olivia wants to launch a new restaurant in the city centre next month.\n","Carter\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine is worried about Kenny's health.\n","He's back from surgery tomorrow.\n","He\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey and Olivia broke up 2 days ago.\n","Olivia cheated on her with numerous girls\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda went dancing classes with Michael yesterday.\n","The instructor needed a partner to show the\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Taylor's friends' daughters bring their bf to her.\n","Isabel hasn't had any\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Theo is leaving on Friday.\n","Toby will come back by train on Monday.\n","Toby\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Brandon will be late.\n","Clara will prepare a report on the absenteeism and lateness\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again and wants to cancel.\n","Olga will reschedule.\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Kate will be Diane's daughter Lorelai.\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew had to call in sick because of a cold.\n","Daniel will drop by after work\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","Alex and Sam are watching 'Millionaires' on tvn.\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Jessica and Angelica have the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Sophie is waiting for a client.\n","Gwen will let Sophie know in 15\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel is on his way to meet Sue.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some salmon and some shaving cream for George\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken started running.\n","Ken's phone battery was almost depleted.\n","Martha's friend had a\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann couldn't come to Ivan's birthday party.\n","Ivan bought her something for her birthday\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Delilah and Rowan are looking for Ashley's pictures on Facebook.\n","Rowan\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj got the letter with the working permission from the government.\n","Magda\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Maria is on her way to the hotel.\n","Peter is still at the convention.\n","Ann\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate, Kai and Terry are going to the Museum of the city of NY.\n","Kate\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at Brooke's house.\n","She will come round at 10 tonight\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica will come to Bradley's birthday party tomorrow at 8 pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla received 250 from Adrian.\n","Camilla needs to check the money.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-10000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-10000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-10000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-10500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-10500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-10500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-11000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-11000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-11000/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-11500\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-11500/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-11500/special_tokens_map.json\n","Saving model checkpoint to bart-tjoin-b6c0.1/checkpoint-12000\n","Configuration saved in bart-tjoin-b6c0.1/checkpoint-12000/config.json\n","Model weights saved in bart-tjoin-b6c0.1/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in bart-tjoin-b6c0.1/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in bart-tjoin-b6c0.1/checkpoint-12000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"output_type":"stream","name":"stdout","text":["----------- 0 --------------\n","------>Predictions by Model\n","A wants to get a puppy for her son.\n","She will take him to the animal\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma wants to buy an advent calendar for her kids.\n","Rob, Lauren and Rob\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant and she doesn't want to talk about it.\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert needs to buy guitar cable.\n","Fred gives him the address of the music shop.\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith will buy some milk and cereals.\n","Megan checked in the drawer next to the\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Evelyn a video.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Tom invited Theresa and Luis for dinner at Tom's new place.\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane will make a reservation for 6 people tonight around 20:00.\n","There is no\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","She has a Texan drawl.\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Haylee is in the dairy section and can't find the coconut milk one she wanted\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy need to hurry to catch the tour.\n","Wendy is at the register\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Cecil went to the Jandia Peninsula.\n","Cecil wants to explore\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Sophie has checked pockets and handbags twice already.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay about bad movies.\n","She will cover \"The Room\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James's biggest dream is to become a voice actor.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy and Alice are going for drinks after work.\n","Poppy has errands to\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will open the door for Caron.\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Giuseppe is dating Gosia.\n","Giuseppe doesn't like games either.\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Mom is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer, Alois and Hilegard are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will be through with the article in a few minutes.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny photo.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Chloe will borrow Sadie's bike on Wednesday evening.\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Olivia wants to launch a new restaurant in the city centre next month.\n","Carter\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine is worried about Kenny's health.\n","He's back from surgery tomorrow.\n","He\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey cheated on Olivia with numerous girls.\n","He got some chick pregnant 2 days ago\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda went dancing classes with Michael yesterday.\n","The instructor needed a partner to show the\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Taylor's friends' daughters bring their bf to her.\n","Isabel hasn't had any\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Theo is leaving on Friday.\n","Toby will come back by train on Monday.\n","Toby\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Brandon will be late.\n","Clara will prepare a report on the absenteeism and lateness\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again and wants to cancel the meeting with Olga.\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Kate will be Diane's daughter Lorelai.\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew has a cold and he feels awful.\n","Daniel will drop by after work to get\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","Alex and Sam are watching 'Millionaires' on tvn.\n","Sam has a\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Jessica and Angelica have the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Sophie is waiting for a client.\n","Gwen will let Sophie know in 15\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel is on his way to meet Sue in a few minutes.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some salmon and some shaving cream for George\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken started running and wanted to track his progress, but his phone battery was almost depleted\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann couldn't come to Ivan's birthday party.\n","Ivan bought her something for her birthday\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Rowan doesn't like Ashley's pictures on Facebook.\n","Ashley has more important stuff to\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj got the letter with the working permission from the government.\n","Magda\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Maria is on her way to the hotel.\n","Ann and Peter are still at the convention\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate, Kai and Terry are going to the Museum of the city of NY.\n","Kate\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at Brooke's house.\n","Brooke will come round at 10 tonight\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica will come to Bradley's birthday party tomorrow at 8 pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla received the money.\n","It usually takes around two days to arrive though.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=12275, training_loss=27163.50544023976, metrics={'train_runtime': 23780.0525, 'train_samples_per_second': 3.097, 'train_steps_per_second': 0.516, 'total_flos': 1.122498977273856e+16, 'train_loss': 27163.50544023976, 'epoch': 5.0})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"B_TUfAgR6aJd","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1670119203248,"user_tz":300,"elapsed":294973,"user":{"displayName":"Hiteshwar Singh","userId":"09663286059140448498"}},"outputId":"6d6cde45-5646-4eec-aafc-af7df0842ef0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 818\n","  Batch size = 3\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [273/273 04:51]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------- 0 --------------\n","------>Predictions by Model\n","A wants to get a puppy for her son.\n","She will take him to the animal\n","----->Predictions Original\n","A will go to the animal shelter tomorrow to get a puppy for her son.\n","They already visited the shelter last Monday and the son chose the puppy.\n","**************************\n","----------- 1 --------------\n","------>Predictions by Model\n","Emma wants to buy an advent calendar for her kids.\n","Rob, Lauren and Rob\n","----->Predictions Original\n","Emma and Rob love the advent calendar.\n","Lauren fits inside calendar various items, for instance, small toys and Christmas decorations.\n","Her children are excited whenever they get the calendar.\n","**************************\n","----------- 2 --------------\n","------>Predictions by Model\n","Madison is pregnant and she doesn't want to talk about it.\n","----->Predictions Original\n","Madison is pregnant but she doesn't want to talk about it.\n","Patricia Stevens got married and she thought she was pregnant.\n","**************************\n","----------- 3 --------------\n","------>Predictions by Model\n","Marla found a pair of boxers under her bed.\n","----->Predictions Original\n","Marla found a pair of boxers under her bed.\n","**************************\n","----------- 4 --------------\n","------>Predictions by Model\n","Robert needs to buy guitar cable.\n","Fred gives him the address of the music shop.\n","----->Predictions Original\n","Robert wants Fred to send him the address of the music shop as he needs to buy guitar cable.\n","**************************\n","----------- 5 --------------\n","------>Predictions by Model\n","Keith will buy some milk and cereals.\n","Megan checked in the drawer next to the\n","----->Predictions Original\n","Megan needn't buy milk and cereals.\n","They're in the drawer next to the fridge.\n","**************************\n","----------- 6 --------------\n","------>Predictions by Model\n","Samantha sends Evelyn a video.\n","----->Predictions Original\n","Samantha and Evelyn after watching the video cannot believe she is able to make that noise.\n","**************************\n","----------- 7 --------------\n","------>Predictions by Model\n","Tom invited Theresa and Luis for dinner at Tom's new place.\n","----->Predictions Original\n","Tom's new place is in Fiesole.\n","Luis and Marion has been there.\n","**************************\n","----------- 8 --------------\n","------>Predictions by Model\n","Jane will make a reservation for 6 people tonight around 20:00.\n","There is no\n","----->Predictions Original\n","Jane made a 9 PM reservation for 6 people tonight at Vegano Resto.\n","**************************\n","----------- 9 --------------\n","------>Predictions by Model\n","Nancy is coming home in 6 weeks.\n","She has a Texan drawl.\n","----->Predictions Original\n","Nancy's working in Texas, but the kids laugh at her Welsh accent.\n","She's coming home in 6 weeks.\n","Earlier than that she's going to travel with 3 other Brits.\n","**************************\n","----------- 10 --------------\n","------>Predictions by Model\n","Laura needs a new printer.\n","Jamie will buy a second hand one.\n","----->Predictions Original\n","Laura is going to buy a printer.\n","**************************\n","----------- 11 --------------\n","------>Predictions by Model\n","Haylee is in the dairy section and can't find the coconut milk one she wanted\n","----->Predictions Original\n","Haylee can't find the coconut milk yoghurt.\n","**************************\n","----------- 12 --------------\n","------>Predictions by Model\n","Norbert and Wendy need to hurry to catch the tour.\n","Wendy is at the register\n","----->Predictions Original\n","Wendy is shopping, but she needs to hurry up to catch the tour.\n","**************************\n","----------- 13 --------------\n","------>Predictions by Model\n","Cecil and Cecil went to the Jandia Peninsula.\n","Cecil wants to explore\n","----->Predictions Original\n","Cecil, Cheryl and Peter went to the Jandia Peninsula today.\n","Cecil would like to explore the south of the island tomorrow, but they will decide what to do after dinner.\n","**************************\n","----------- 14 --------------\n","------>Predictions by Model\n","Sophie has checked pockets and handbags twice already.\n","----->Predictions Original\n","Sophie still hasn't found it despite checking pockets and handbags twice.\n","**************************\n","----------- 15 --------------\n","------>Predictions by Model\n","Rosie has to write an essay about bad movies.\n","She will cover \"The Room\n","----->Predictions Original\n","Dennis and Elle are helping Rosie think of bad movies for her essay.\n","**************************\n","----------- 16 --------------\n","------>Predictions by Model\n","James's biggest dream is to become a voice actor.\n","----->Predictions Original\n","James has a dream of becoming a voice actor.\n","He considers making a home radio station.\n","**************************\n","----------- 17 --------------\n","------>Predictions by Model\n","Poppy and Alice are going for drinks after work.\n","Poppy has errands to\n","----->Predictions Original\n","Poppy and Alice are meeting for drinks after work at Nick's at 5:30.\n","Alice fancies Fred, she will invite him and a bunch of other coworkers.\n","**************************\n","----------- 18 --------------\n","------>Predictions by Model\n","Caron is out from 12.\n","Sash will open the door for Caron.\n","----->Predictions Original\n","Sash needs to see Caron who'll be out from 12.\n","**************************\n","----------- 19 --------------\n","------>Predictions by Model\n","Giuseppe is dating Gosia.\n","Giuseppe doesn't like games either.\n","----->Predictions Original\n","Matteo is not sure about his relationship with Gosia but likes her a lot.\n","**************************\n","----------- 20 --------------\n","------>Predictions by Model\n","Mom is calling Ramzi for supper.\n","----->Predictions Original\n","Ramzi and Jannette are going for supper.\n","**************************\n","----------- 21 --------------\n","------>Predictions by Model\n","Jeniffer, Alois and Hilegard are preparing ravioli.\n","----->Predictions Original\n","Jeniffer is preparing ravioli following her grandmothers recipe.\n","**************************\n","----------- 22 --------------\n","------>Predictions by Model\n","Lawrence will be through with the article in a few minutes.\n","----->Predictions Original\n","Lawrence will finish writing the article soon.\n","**************************\n","----------- 23 --------------\n","------>Predictions by Model\n","Chad sent Brennen a funny photo.\n","----->Predictions Original\n","Chad has sent Brennen a funny photo.\n","Brennen does not find it very funny.\n","**************************\n","----------- 24 --------------\n","------>Predictions by Model\n","Chloe will borrow Sadie's bike on Wednesday evening.\n","----->Predictions Original\n","Sadie will borrow Chloe's bike on Wednesday evening.\n","She has a dentist appointment on Thursday after work.\n","**************************\n","----------- 25 --------------\n","------>Predictions by Model\n","Olivia wants to launch a new restaurant in the city centre next month.\n","Carter\n","----->Predictions Original\n","Carter is launching a restaurant business next month.\n","Olivia wants him to include a restaurant she's working for in the discount app.\n","They will meet in person to discuss it.\n","**************************\n","----------- 26 --------------\n","------>Predictions by Model\n","Kristine is worried about Kenny's health.\n","He's back from surgery tomorrow.\n","He\n","----->Predictions Original\n","Kenny had a surgery, as Kristine reports.\n","He will have another surgery tomorrow.\n","Guy will come to St. Mark's Hospital near Asda to stay with Kristine.\n","**************************\n","----------- 27 --------------\n","------>Predictions by Model\n","Joey cheated on Olivia with numerous girls.\n","He got some chick pregnant 2 days ago\n","----->Predictions Original\n","Skyler and Adam are surprised that Joey and Olivia broke up.\n","**************************\n","----------- 28 --------------\n","------>Predictions by Model\n","Amanda went dancing classes with Michael yesterday.\n","The instructor needed a partner to show the\n","----->Predictions Original\n","Amanda goes to dancing classes with Michael.\n","She volunteered to show the English Waltz steps with the instructor yesterday.\n","Amanda is shy and goes to therapy.\n","**************************\n","----------- 29 --------------\n","------>Predictions by Model\n","Taylor's friends' daughters bring their bf to her.\n","Isabel hasn't had any\n","----->Predictions Original\n","Taylor wants to meet Isabel's boyfriend but she has never had any.\n","**************************\n","----------- 30 --------------\n","------>Predictions by Model\n","Theo is leaving on Friday.\n","Toby will come back by train on Monday.\n","Toby\n","----->Predictions Original\n","Theo's going to stay near Torino in the region of Italian Alpes.\n","Toby wants to join the trip.\n","Theo agrees and will pick Toby up on Friday at 7 am.\n","**************************\n","----------- 31 --------------\n","------>Predictions by Model\n","Brandon will be late.\n","Clara will prepare a report on the absenteeism and lateness\n","----->Predictions Original\n","Brandon is late again.\n","Clara will prepare a report on the absenteeism and lateness for Phil by Friday.\n","**************************\n","----------- 32 --------------\n","------>Predictions by Model\n","Suzie is sick again and wants to cancel the meeting with Olga.\n","----->Predictions Original\n","Olga and Suzie will postpone their meeting due to Suzie's sickness.\n","**************************\n","----------- 33 --------------\n","------>Predictions by Model\n","Kate will be Diane's daughter Lorelai.\n","----->Predictions Original\n","Diane is pregnant and can't wait to give birth, she thinks the waiting is the worst.\n","Kate thinks she'll be an amazing mother.\n","**************************\n","----------- 34 --------------\n","------>Predictions by Model\n","Andrew has a cold and he feels awful.\n","Daniel will drop by after work to get\n","----->Predictions Original\n","Andrew has a cold.\n","Daniel will buy him some medication.\n","**************************\n","----------- 35 --------------\n","------>Predictions by Model\n","Alex and Sam are watching 'Millionaires' on tvn.\n","Sam has a\n","----->Predictions Original\n","Alex and Sam are watching Millionaires.\n","**************************\n","----------- 36 --------------\n","------>Predictions by Model\n","Jessica and Angelica have the cinnamon cookies recipe.\n","----->Predictions Original\n","Angelica sent the cinnamon cookies recipe at Kelly's request.\n","**************************\n","----------- 37 --------------\n","------>Predictions by Model\n","Sophie is waiting for a client.\n","Gwen will let Sophie know in 15\n","----->Predictions Original\n","Sophie is waiting for a client, who is late.\n","She will meet Gwen later.\n","**************************\n","----------- 38 --------------\n","------>Predictions by Model\n","Daniel is on his way to meet Sue in a few minutes.\n","----->Predictions Original\n","Daniel is with the Volvo on his way and will be there soon.\n","Sue is going downstairs to meet him.\n","**************************\n","----------- 39 --------------\n","------>Predictions by Model\n","Betty is going to CVS to buy some salmon and some shaving cream for George\n","----->Predictions Original\n","George is making salmon and stuffed squash for dinner.\n","Betty will buy a shaving cream at CVS at his request,\n","**************************\n","----------- 40 --------------\n","------>Predictions by Model\n","Ken started running and wanted to track his progress, but his phone battery was almost depleted\n","----->Predictions Original\n","Ken has installed an app for running but it is not working properly on his phone.\n","**************************\n","----------- 41 --------------\n","------>Predictions by Model\n","Ann couldn't come to Ivan's birthday party.\n","Ivan bought her something for her birthday\n","----->Predictions Original\n","Ivan and Ann will meet next week.\n","**************************\n","----------- 42 --------------\n","------>Predictions by Model\n","Rowan doesn't like Ashley's pictures on Facebook.\n","Ashley has more important stuff to\n","----->Predictions Original\n","Ashley posted some nude photos on her fb page.\n","**************************\n","----------- 43 --------------\n","------>Predictions by Model\n","Mikolaj got the letter with the working permission from the government.\n","Magda\n","----->Predictions Original\n","Mikolaj's wife needs a work permit as a foreigner.\n","Government officials missed the deadline for sending it and will need another month.\n","**************************\n","----------- 44 --------------\n","------>Predictions by Model\n","Maria is on her way to the hotel.\n","Ann and Peter are still at the convention\n","----->Predictions Original\n","Thomas, Ann and Maria will have lunch together at the hotel.\n","Ann is already in the 3rd floor lobby at the red table.\n","**************************\n","----------- 45 --------------\n","------>Predictions by Model\n","Sus is sleepy and doesn't want to work.\n","----->Predictions Original\n","Sus and Val don't want to work and are sleepy.\n","**************************\n","----------- 46 --------------\n","------>Predictions by Model\n","Kate, Kai and Terry are going to the Museum of the city of NY.\n","Kate\n","----->Predictions Original\n","Kate is at the Guggenheim Museum now, but will be in the Museum of the City of New York around 2-2:30.\n","Kai may join her.\n","Ish won't.\n","Terry will join them for a coffee after they finish visiting the museum.\n","Terry has already seen the museum.\n","**************************\n","----------- 47 --------------\n","------>Predictions by Model\n","Cathy left her sunglasses at Brooke's house.\n","Brooke will come round at 10 tonight\n","----->Predictions Original\n","Cathy left her sunglasses at Broke's house.\n","She will come collect them at 10.\n","**************************\n","----------- 48 --------------\n","------>Predictions by Model\n","Frederica will come to Bradley's birthday party tomorrow at 8 pm.\n","----->Predictions Original\n","Bradley will come to Frederica's birthday party tomorrow at 8pm.\n","**************************\n","----------- 49 --------------\n","------>Predictions by Model\n","Camilla received the money.\n","It usually takes around two days to arrive though.\n","----->Predictions Original\n","Camilla still hasn't received the 250.\n","She will check and let Adrian know.\n","Money usually takes around two days to arrive.\n","**************************\n"]},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 5.0,\n"," 'eval_gen_len': 17.9205,\n"," 'eval_loss': 3.438715934753418,\n"," 'eval_rouge1': 47.4304,\n"," 'eval_rouge2': 24.3846,\n"," 'eval_rougeL': 40.3954,\n"," 'eval_rougeLsum': 43.7979,\n"," 'eval_runtime': 294.9296,\n"," 'eval_samples_per_second': 2.774,\n"," 'eval_steps_per_second': 0.926}"]},"metadata":{},"execution_count":26}]}]}